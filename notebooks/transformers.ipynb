{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the Transformer Architecture\n",
    "\n",
    "most of the code here is a simplified version of [Karpathy's nanoGPT codebase](https://github.com/karpathy/nanoGPT/) -- check that out if you want to see a more practical implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from jaxtyping import Int, Float\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import transformers\n",
    "\n",
    "from utils.get_books import get_gutenberg_book, get_many_books\n",
    "from utils.mermaid import mm\n",
    "# from utils.analyze_vocab import analyze_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic auto-reload for local development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to install required packages:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So:\n",
    "- dense networks fail because they re-learn the same thing at every position\n",
    "- convolutional networks give the *spatial* prior to our networks, great for images\n",
    "- RNNs give the *temporal* prior to our networks, great for sequences -- but they decay over time\n",
    "\n",
    "When we actually process language, we care about more than just *local* relationships of this sort:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/8/8c/Parse2.jpg)\n",
    "\n",
    "Many scientists tried for a very long time to try to encode parse trees in machines, but using human knowledge ended up being far less effective than letting the machines pick it up themselves.\n",
    "\n",
    "The key insight of transformers and modern large language models is the *attention mechanism:*\n",
    "\n",
    "> Given some sequence of inputs $[x_1, \\ldots, x_n]$, when trying to predict the next token $x_{n+1}$, long range dependencies can be captured by letting a network choose which previous tokens to pay *attention* to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> note on notation: we're now switching to $x_i$ being already embedded vectors in $\\R^{d_m}$, rather than one-hot vectors in $\\R^{d_V}$\n",
    "\n",
    "The attention mechanism is a map $\\mathbb{A} : \\R^{d_m} \\times (\\R^{d_m})^{n_c} \\to \\R^{d_m}$ which takes a *query* $x_q$ and a *key* $x_k$ and produces a weighted sum of the values. We first consider the computation of scalar attention $A_s: \\R^{d_m} \\times \\R^{d_m} \\to \\R$ for some head $s$.\n",
    "\n",
    "$$ A_s(x_q, x_k) = \\sigma \\left( c \\cdot x_q Q_s (x_k K_s)^T \\right) $$\n",
    "\n",
    "What are all these symbols? Firstly, we define $d_h$: the *head dimension*. We usually pick a number of heads `n_heads` and set $d_h = d_m / n_h$. Think of each head as a separate attention mechanism, kind of like different kernels in a convolutional layer.\n",
    "\n",
    "- $c$ is a constant scalar, usually set to $\\frac{1}{\\sqrt{d_h}}$\n",
    "- $Q_s, K_s \\in \\R^{d_m \\times d_h}$ are learned linear maps - we have a different set of weights for each head\n",
    "- $\\sigma$ is the softmax function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, once we have the scalar attention $A_s$, we can define the full attention map $A: \\R^{d_m} \\times \\R^{d_m} \\to \\R^{d_m}$ as follows:\n",
    "\n",
    "$$ \\mathbb{A}(x_q) = [ A_s(x_q, x_k) x_q V_s ]_{s \\in \\N_{n_h}} $$\n",
    "\n",
    "$$ = \\left[ \\sigma \\left( \\frac{1}{\\sqrt{d_h}} \\cdot x_q Q_s (x_k K_s)^T \\right) x_q V_s \\right]_{s \\in \\N_{n_h}} $$\n",
    "\n",
    "where $W^Q_i, W^K_i, W^V_i \\in \\R^{d_m \\times d_h}$ are learned linear maps, and $V_i \\in \\R^{d_m}$ are learned vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up configuration\n",
    "\n",
    "- `d_model` $= d_m$\n",
    "- `d_vocab` $= d_v$\n",
    "- `n_context` $= n_c$\n",
    "- `n_layer` $= n_L$\n",
    "- `n_head` $= n_h$\n",
    "- `d_head` $= d_h = \\frac{d_m}{n_h}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(kw_only=True)\n",
    "class GPTConfig:\n",
    "    \"\"\"defaults are the gpt-2 model\"\"\"\n",
    "    d_model: int = 768\n",
    "    d_vocab: int = 50257\n",
    "    n_context: int = 1024\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "\n",
    "    @property\n",
    "    def d_head(self):\n",
    "        assert self.d_model % self.n_head == 0, f\"'{self.d_model = }' must be divisible by '{self.n_head = }': {self.d_model} % {self.n_head} == {self.d_model % self.n_head}\"\n",
    "        return self.d_model // self.n_head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I kind of lied to you earlier about the attention heads -- they don't actually operate over a pair of vectors, since the softmax gets applied over all items for that key.\n",
    "\n",
    "Additionally, we implement *causal masking* by adding a matrix of $-\\infty$.\n",
    "\n",
    "\n",
    "Given some input $x \\in \\R^{n_c \\times d_m}$, we can express our attention head $\\mathbb{A}(x): \\R^{n_c \\times d_m} \\to \\R^{n_c \\times d_h}$ as:\n",
    "\n",
    "\n",
    "$$\n",
    "\t\\mathbb{A}(x) := \\left( \\frac{\\texttt{softmax}(x W_Q (x W_K)^T)}{\\sqrt{d_h}} + M \\right) x W_V\n",
    "$$\n",
    "\n",
    "Where $M$ is a causal mask, and\n",
    "\n",
    "$$ \n",
    "\t[M]_{i,j} = \\begin{cases} \n",
    "\t\t0 & i \\geq j \\\\\n",
    "\t\t-\\infty & i < j \\\\\n",
    "\t\\end{cases}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        # store dimensions\n",
    "        self.n_head: int = config.n_head\n",
    "        self.d_model: int = config.d_model\n",
    "        self.n_context: int = config.n_context\n",
    "\n",
    "        # concatenating the outputs of the heads should give us d_model, but this check is done in GPTConfig\n",
    "        self.d_head: int = config.d_head\n",
    "\n",
    "        # coefficient for scaling the dot product of the query and key in the attention calculation\n",
    "        self.sqrt_dim: float = 1.0 / math.sqrt(self.d_head)\n",
    "\n",
    "        # key, query, value projections\n",
    "        self.W_K: nn.Module = nn.Linear(self.d_model, self.d_head)\n",
    "        self.W_Q: nn.Module = nn.Linear(self.d_model, self.d_head)\n",
    "        self.W_V: nn.Module = nn.Linear(self.d_model, self.d_head)\n",
    "\n",
    "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "        # `register_buffer` means it's not a trainable parameter\n",
    "        self.register_buffer(\n",
    "            \"causal_mask\", \n",
    "            torch.tril(\n",
    "                torch.ones(config.n_context, config.n_context)\n",
    "            )\n",
    "            .view(1, 1, config.n_context, config.n_context)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Float[torch.Tensor, \"batch n_ctx d_model\"]) -> Float[torch.Tensor, \"batch n_ctx d_head\"]:\n",
    "        assert x.ndim == 3, str(x.shape)\n",
    "        B, n_ctx, d_model = x.shape # batch size, sequence length, embedding dimensionality (d_model)\n",
    "        assert d_model == self.d_model, str(x.shape)\n",
    "        # assert n_ctx == self.n_context, str(x.shape)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q: Float[torch.Tensor, \"batch n_ctx d_head\"] = self.W_Q(x)\n",
    "        k: Float[torch.Tensor, \"batch n_ctx d_head\"] = self.W_K(x)\n",
    "        v: Float[torch.Tensor, \"batch n_ctx d_head\"] = self.W_V(x)\n",
    "\n",
    "        # self-attention\n",
    "        # (B, n_ctx, d_h) x (B, d_h, n_ctx) -> (B, n_ctx, n_ctx)\n",
    "        att = (q @ k.transpose(-2, -1)) * self.sqrt_dim\n",
    "        \n",
    "        # autoregressive (causal) masking\n",
    "        att = att.masked_fill(\n",
    "            self.causal_mask[:,:n_ctx,:n_ctx] == 0, \n",
    "            float('-inf'),\n",
    "        )\n",
    "\n",
    "        # softmax\n",
    "        att = F.softmax(att, dim=-1)\n",
    "\n",
    "        # apply the self-attention to the values\n",
    "        # (B, n_ctx, n_ctx) x (B, n_ctx, d_h) -> (B, n_ctx, d_h)\n",
    "        output = att @ v\n",
    "        return output.view(B, n_ctx, self.d_head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, you might notice that we also add another dimension `B` -- this is the *batch dimension*, and speeds things up a lot when we want to compute gradients over a set of samples. PyTorch broadcasts all operations over that batch dimension, so all the calculations are equivalent.\n",
    "\n",
    "Let's check to see if the dimensions are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionHead(\n",
      "  (W_K): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (W_Q): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (W_V): Linear(in_features=64, out_features=16, bias=True)\n",
      ")\n",
      "cfg.d_head = 16\n",
      "x.shape = torch.Size([1, 128, 64])\n",
      "A(x).shape = torch.Size([1, 128, 16])\n"
     ]
    }
   ],
   "source": [
    "cfg: GPTConfig = GPTConfig(\n",
    "\tn_context=128,\n",
    "\td_model=64,\n",
    "\tn_head=4,\n",
    ")\n",
    "A: AttentionHead = AttentionHead(cfg)\n",
    "print(A)\n",
    "\n",
    "x = torch.randn(1, cfg.n_context, cfg.d_model)\n",
    "print(f\"{cfg.d_head = }\")\n",
    "print(f\"{x.shape = }\")\n",
    "print(f\"{A(x).shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "does that look correct?\n",
    "\n",
    "\n",
    "Now, let's take a look at that causal mask $M$, referred to as `causal_mask` in the code. You'll note that when we define it, it's actually a matrix of $\\{0, 1\\}$ and not $\\{-\\infty, 0\\}$. However, in the `.forward()` function, we use `masked_fill` to set the elements of `attn` to $-\\infty$ where $M$ is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(A.causal_mask[0, 0].cpu().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-headed attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of each attention head as learning some *concept* -- but we have many concepts we might need to learn, hence multiple attention heads. Let's call this function $\\text{MHA}(x) : \\R^{n_c \\times d_m} \\to \\R^{n_c \\times d_m}$. Given attention heads $[\\mathbb{A}_1, \\ldots, \\mathbb{A}_{n_h}]$, we compute `MHA` as:\n",
    "\n",
    "\n",
    "$$\n",
    "\t\\texttt{MHA}(x) = \\left[\\begin{array}{c} \n",
    "\t\t\\mathbb{A}_1(x) \\\\ \\hline\n",
    "\t\t\\mathbb{A}_2(x) \\\\ \\hline\n",
    "\t\t\\vdots \\\\ \\hline\n",
    "\t\t\\mathbb{A}_{n_h}(x)\n",
    "\t\\end{array}\\right]\n",
    "\t\\cdot [x W_O]\n",
    "$$\n",
    "\n",
    "Where $W_O \\in \\R^{d_m \\times d_m}$ is just another learned linear map.\n",
    "\n",
    "\n",
    "In our implementation, for readability and simplicity, we compute the attention heads one by one and then concatenate them. This is really really inefficient -- in reality you would do this all in one matrix multiplication, but the indexing for that gets complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "\tdef __init__(self, config: GPTConfig):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.n_head: int = config.n_head\n",
    "\t\tself.d_head: int = config.d_model // config.n_head\n",
    "\t\tself.d_model: int = config.d_model\n",
    "\n",
    "\t\t# attention heads\n",
    "\t\tself.attention_heads: nn.ModuleList = nn.ModuleList([\n",
    "\t\t\tAttentionHead(config) \n",
    "\t\t\tfor _ in range(self.n_head)\n",
    "\t\t])\n",
    "\n",
    "\t\t# output projection\n",
    "\t\tself.W_O: nn.Module = nn.Linear(self.d_model, self.d_model)\n",
    "\n",
    "\n",
    "\tdef forward(self, x: Float[torch.Tensor, \"batch n_ctx d_model\"]) -> Float[torch.Tensor, \"batch n_ctx d_model\"]:\n",
    "\t\tassert x.ndim == 3, str(x.shape)\n",
    "\t\t# apply all attention heads and concatenate their outputs\n",
    "\t\t# note: in reality, you would do this all in one tensor\n",
    "\t\t# we split the attention heads up to make it easier to understand\n",
    "\t\tatt = torch.cat(\n",
    "\t\t\t[\n",
    "\t\t\t\thead(x) \n",
    "\t\t\t\tfor head in self.attention_heads\n",
    "\t\t\t],\n",
    "\t\t\tdim=-1,\n",
    "\t\t)\n",
    "\t\tassert len(att.shape) == 3, str(att.shape)\n",
    "\n",
    "\t\t# output projection\n",
    "\t\t# (B, n_ctx, d_head * n_head) -> (B, n_ctx, d_model)\n",
    "\t\toutput = self.W_O(att)\n",
    "\t\tassert output.shape == x.shape, str(output.shape)\n",
    "\t\treturn output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 1: a Transformer](assets/transformers_robot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A transformer is made up of *Transformer Blocks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIFREOwpzdWJncmFwaCBUcmFuc2Zvcm1lckJsb2NrCiAgICB4KCh4KSkKICAgIHggLS0+IGxuXzEKCWxuXzEgLS0+IE1IQQogICAgeigoeikpCglNSEEgLS0+IHoKICAgIHggLS0+IHoKICAgIHogLS0+IGxuXzIKCWxuXzIgLS0+IE1MUAoJeSgoeSkpCiAgIAlNTFAgLS0+IHkKICAgIHogLS0+IHkKZW5kCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mm(\"\"\"\n",
    "graph TD;\n",
    "subgraph TransformerBlock\n",
    "    x((x))\n",
    "    x --> ln_1\n",
    "\tln_1 --> MHA\n",
    "    z((z))\n",
    "\tMHA --> z\n",
    "    x --> z\n",
    "    z --> ln_2\n",
    "\tln_2 --> MLP\n",
    "\ty((y))\n",
    "   \tMLP --> y\n",
    "    z --> y\n",
    "end\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\tdef __init__(self, config: GPTConfig):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\t# layernorm, attention, another layernorm, mlp\n",
    "\t\tself.ln_1: nn.Module = nn.LayerNorm(config.d_model)\n",
    "\t\tself.attention: nn.Module = MultiHeadedAttention(config)\n",
    "\t\tself.ln_2: nn.Module = nn.LayerNorm(config.d_model)\n",
    "\t\tself.mlp: nn.Module = nn.Sequential(\n",
    "\t\t\tnn.Linear(config.d_model, 4 * config.d_model),\n",
    "\t\t\tnn.GELU(),\n",
    "\t\t\tnn.Linear(4 * config.d_model, config.d_model),\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x: Float[torch.Tensor, \"batch n_ctx d_model\"]) -> Float[torch.Tensor, \"batch n_ctx d_model\"]:\n",
    "\t\tz = x + self.attention(self.ln_1(x))\n",
    "\t\treturn z + self.mlp(self.ln_2(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's this `LayerNorm` thing?\n",
    "\n",
    "see: https://arxiv.org/abs/1607.06450\n",
    "\n",
    "$$ \\texttt{LayerNorm}(x) = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally, for the GPT itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIFREOwpzdWJncmFwaCBHUFQKICAgIHByb21wdCgocHJvbXB0KSkKICAgIHd0ZVtcVG9rZW4gRW1iZWRkaW5nL10KCXdwZXt7UG9zaXRpb25hbCBFbmNvZGluZ319CiAgICBUQjFbW1RyYW5zZm9ybWVyQmxvY2tfMV1dCiAgICBUQjJbW1RyYW5zZm9ybWVyQmxvY2tfMl1dCglUQl9kb3Rzey4uLn0KICAgIFRCbkxbW1RyYW5zZm9ybWVyQmxvY2tfbl9MXV0KICAgIGxuX2ZbW0xheWVyTm9ybV1dCiAgICBsbV9oZWFkWy9EZS1FbWJlZGRpbmdcXQogICAKICAgIHByb21wdCAtLT4gd3RlCiAgICBwcm9tcHQgLS0+IHdwZQogICAgd3RlIC0tPiBUQjEKICAgIHdwZSAtLT4gVEIxCiAgICBUQjEgLS0+IFRCMgogICAgVEIyIC0tPiBUQl9kb3RzCiAgICBUQl9kb3RzIC0tPiBUQm5MCiAgICBUQm5MIC0tPiBsbl9mCiAgICBsbl9mIC0tPiBsbV9oZWFkCmVuZAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph TD;\n",
    "subgraph GPT\n",
    "    prompt((prompt))\n",
    "    wte[\\Token Embedding/]\n",
    "\twpe{{Positional Encoding}}\n",
    "    TB1[[TransformerBlock_1]]\n",
    "    TB2[[TransformerBlock_2]]\n",
    "\tTB_dots{...}\n",
    "    TBnL[[TransformerBlock_n_L]]\n",
    "    ln_f[[LayerNorm]]\n",
    "    lm_head[/De-Embedding\\]\n",
    "   \n",
    "    prompt --> wte\n",
    "    prompt --> wpe\n",
    "    wte --> TB1\n",
    "    wpe --> TB1\n",
    "    TB1 --> TB2\n",
    "    TB2 --> TB_dots\n",
    "    TB_dots --> TBnL\n",
    "    TBnL --> ln_f\n",
    "    ln_f --> lm_head\n",
    "end\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "\tdef __init__(self, config: GPTConfig, tokenizer: transformers.PreTrainedTokenizer):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.config: GPTConfig = config\n",
    "\t\tself.tokenizer: transformers.PreTrainedTokenizer = tokenizer\n",
    "\t\tassert config.d_vocab >= tokenizer.vocab_size\n",
    "\n",
    "\t\t# token and positional embeddings\n",
    "\t\tself.token_embeddings: nn.Module = nn.Embedding(config.d_vocab, config.d_model)\n",
    "\t\tself.positional_embeddings: nn.Module = nn.Embedding(config.n_context, config.d_model)\n",
    "\n",
    "\t\t# transformer\n",
    "\t\tself.transformer_blocks: nn.ModuleList = nn.ModuleList([\n",
    "\t\t\tTransformerBlock(config) \n",
    "\t\t\tfor _ in range(config.n_layer)\n",
    "\t\t])\n",
    "\n",
    "\t\t# language model head\n",
    "\t\tself.ln_f: nn.Module = nn.LayerNorm(config.d_model)\n",
    "\t\tself.lm_head: nn.Module = nn.Linear(config.d_model, config.d_vocab, bias=False)\n",
    "\n",
    "\tdef forward(\n",
    "\t\t\tself, \n",
    "\t\t\tx: Int[torch.Tensor, \"batch n_ctx\"],\n",
    "\t\t\ttargets: Int[torch.Tensor, \"batch n_ctx\"]|None = None,\n",
    "\t\t) -> tuple:\n",
    "\t\t\"\"\"returns a tuple of (logits, loss) where loss=None if targets is None\"\"\"\n",
    "\t\tassert x.ndim == 2, str(x.shape)\n",
    "\n",
    "\t\t# calculate token and positional embeddings and sum them\n",
    "\t\tx_res = (\n",
    "\t\t\tself.token_embeddings(x) \n",
    "\t\t\t+ self.positional_embeddings(torch.arange(x.size(1), device=x.device))\n",
    "\t\t)\n",
    "\n",
    "\t\tassert x_res.ndim == 3, str(x.shape)\n",
    "\n",
    "\t\t# transformer blocks\n",
    "\t\tfor i, block in enumerate(self.transformer_blocks):\n",
    "\t\t\tx_res = block(x_res)\n",
    "\n",
    "\t\t# language model head\n",
    "\t\tlogits: Float[torch.Tensor, \"batch n_ctx d_vocab\"] = self.lm_head(self.ln_f(x_res))\n",
    "\n",
    "\t\tloss = None\n",
    "\t\tif targets is not None:\n",
    "\t\t\tloss = F.cross_entropy(\n",
    "\t\t\t\tlogits.transpose(1, 2),\n",
    "\t\t\t\ttargets,\n",
    "\t\t\t\tignore_index=-1,\n",
    "\t\t\t)\n",
    "\n",
    "\t\treturn logits, loss\n",
    "\t\n",
    "\t@torch.no_grad()\n",
    "\tdef generate(\n",
    "\t\tself,\n",
    "\t\tprompt: str|list[int]|Int[torch.Tensor, \"* n_ctx\"],\n",
    "\t\tmax_new_tokens: int = 128,\n",
    "\t\ttemperature: float = 1.0,\n",
    "\t) -> str:\n",
    "\n",
    "\t\t# convert prompt to string and tensor versions\n",
    "\t\tprompt_str: str\n",
    "\t\tprompt_tensor: Int[torch.Tensor, \"1 n_ctx\"]\n",
    "\t\tif isinstance(prompt, str):\n",
    "\t\t\tprompt_str = prompt\n",
    "\t\t\tprompt_tensor = torch.tensor(self.tokenizer.encode(prompt_str), dtype=torch.long).unsqueeze(0) # add batch dim\n",
    "\t\telif isinstance(prompt, list):\n",
    "\t\t\tprompt_str = self.tokenizer.decode(prompt)\n",
    "\t\t\tprompt_tensor = torch.tensor(prompt, dtype=torch.long).unsqueeze(0) # add batch dim\n",
    "\t\telif isinstance(prompt, torch.Tensor):\n",
    "\t\t\tif prompt.ndim == 1:\n",
    "\t\t\t\tprompt = prompt.unsqueeze(0) # add batch dim\n",
    "\t\t\tassert prompt.ndim == 2\n",
    "\n",
    "\t\t\tprompt_str = self.tokenizer.decode(prompt[0].tolist())\n",
    "\t\t\tprompt_tensor = prompt\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(f\"prompt must be a string, list of ints, or PyTorch tensor\")\n",
    "\t\t\n",
    "\t\t# check tensor dims\n",
    "\t\tassert isinstance(prompt_str, str) \n",
    "\t\tassert isinstance(prompt_tensor, torch.Tensor)\n",
    "\t\tassert prompt_tensor.ndim == 2 \n",
    "\t\tassert prompt_tensor.shape[0] == 1\n",
    "\n",
    "\t\t#  device\n",
    "\t\tprompt_tensor = prompt_tensor.to(self.device)\n",
    "\n",
    "\t\t# pad the prompt if necessary\n",
    "\t\tif prompt_tensor.shape[1] < self.config.n_context:\n",
    "\t\t\tprompt_tensor = F.pad(prompt_tensor, (0, self.config.n_context - prompt_tensor.shape[1]), value=self.tokenizer.pad_token_id)\n",
    "\n",
    "\t\tassert prompt_tensor.shape[1] == self.config.n_context\n",
    "\n",
    "\t\t# iterate until max_new_tokens is reached, or an end-of-sequence token is generated\n",
    "\t\tcompletions: list[int] = list()\n",
    "\t\tfor _ in range(max_new_tokens):\n",
    "\t\t\t# truncate sequence to block size\n",
    "\t\t\tprompt_len: int = prompt_tensor.shape[1]\n",
    "\t\t\tif prompt_len > self.config.n_context:\n",
    "\t\t\t\tprompt_tensor = prompt_tensor[:, -self.config.n_context:]\n",
    "\n",
    "\t\t\t# forward the model to get the logits for the index in the sequence\n",
    "\t\t\tlogits, _ = self(prompt_tensor)\n",
    "\n",
    "\t\t\t# pluck the logits at the final step and scale by desired temperature\n",
    "\t\t\tlogits = logits[:, -1, :] / temperature\n",
    "\n",
    "\t\t\t# apply softmax to convert logits to (normalized) probabilities\n",
    "\t\t\tprobs = F.softmax(logits, dim=-1)\n",
    "\n",
    "\t\t\t# sample from the distribution\n",
    "\t\t\tidx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "\t\t\t# append sampled index to the running sequence and continue\n",
    "\t\t\tidx = torch.cat((prompt_tensor, idx_next), dim=1)\n",
    "\n",
    "\t\t\t# append the token to the running completions\n",
    "\t\t\tcompletions.append(int(idx_next[0, 0]))\n",
    "\n",
    "\t\t\t# check if end of sequence token is generated\n",
    "\t\t\tif idx_next == self.tokenizer.eos_token_id:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\treturn self.tokenizer.decode(completions)\n",
    "\n",
    "\t@property\n",
    "\tdef n_params(self) -> int:\n",
    "\t\treturn sum(p.numel() for p in self.parameters())\n",
    "\t\n",
    "\t@property\n",
    "\tdef device(self) -> torch.device:\n",
    "\t\tdevice_set: set[torch.device] = set(p.device for p in self.parameters())\n",
    "\t\tassert len(device_set) == 1, device_set\n",
    "\t\treturn next(iter(device_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting book 84...\n",
      "\t426812 characters read\n",
      "Getting book 15...\n",
      "\t1241057 characters read\n",
      "Getting book 18...\n",
      "\t1191616 characters read\n",
      "Getting book 82...\n",
      "\t1125004 characters read\n",
      "Getting book 996...\n",
      "\t2342280 characters read\n",
      "Getting book 2600...\n",
      "\t3274016 characters read\n"
     ]
    }
   ],
   "source": [
    "text_data: str = ' '.join(get_many_books([84, 15, 18, 82, 996, 2600]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "\tdef __init__(\n",
    "\t\t\tself, \n",
    "\t\t\ttext: str, \n",
    "\t\t\ttokenizer: transformers.PreTrainedTokenizer,\n",
    "\t\t\tn_context: int,\n",
    "\t\t\tensure_n_context_match: bool = True,\n",
    "\t\t):\n",
    "\t\t# tokenize the text\n",
    "\t\ttokenized_text: list[int] = tokenizer.encode(text)\n",
    "\t\tself.total_tokens: int = len(tokenized_text)\n",
    "\n",
    "\t\t# trim the last tokens to make sure the length is a multiple of n_context\n",
    "\t\tif ensure_n_context_match:\n",
    "\t\t\ttokenized_text = tokenized_text[:-(len(tokenized_text) % n_context)]\n",
    "\t\t\tself.total_tokens = len(tokenized_text)\n",
    "\n",
    "\t\t# split the text into examples of length n_context\n",
    "\t\t# this means that text will often start in the middle of a sentence\n",
    "\t\t# in reality, we might want to do this a bit smarter\n",
    "\t\tself.examples: list[list[int]] = [\n",
    "\t\t\ttokenized_text[i:i+n_context] \n",
    "\t\t\tfor i in range(0, len(tokenized_text), n_context)\n",
    "\t\t]\n",
    "\n",
    "\tdef __len__(self) -> int:\n",
    "\t\treturn len(self.examples)\n",
    "\t\n",
    "\tdef __getitem__(self, i: int) -> Float[torch.Tensor, \"n_ctx\"]:\n",
    "\t\treturn torch.tensor(self.examples[i], dtype=torch.long)\n",
    "\t\n",
    "\tdef example_lengths(self) -> Counter[int]:\n",
    "\t\treturn Counter(len(ex) for ex in self.examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "\tmodel: GPT,\n",
    "\ttext: str,\n",
    "\toptimizer: torch.optim.Optimizer,\n",
    "\tdevice: torch.device = (\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "\tbatch_size: int = 8,\n",
    "\tmax_batches: int|None = None,\n",
    "\tprint_interval: int = 100,\n",
    "\tepochs: int = 1,\n",
    ") -> tuple[GPT, list[dict]]:\n",
    "\t\n",
    "\t# move model to device\n",
    "\tprint(f\"moving model to device: {device}\")\n",
    "\tmodel.to(device)\n",
    "\t\n",
    "\t# set up data\n",
    "\tprint(f\"setting up dataset from text of length {len(text)}\")\n",
    "\tdataset: TextDataset = TextDataset(\n",
    "\t\ttext=text, \n",
    "\t\ttokenizer=model.tokenizer, \n",
    "\t\tn_context=model.config.n_context,\n",
    "\t)\n",
    "\tprint(f\"\\tset up dataset with {len(dataset)} examples, example lengths: {dataset.example_lengths()}\")\n",
    "\n",
    "\tprint(f\"setting up dataloader from {len(dataset)} examples\")\n",
    "\tdataloader: DataLoader = DataLoader(\n",
    "\t\tdataset, \n",
    "\t\tbatch_size=batch_size, \n",
    "\t\tshuffle=True,\n",
    "\t)\n",
    "\tprint(f\"\\tset up dataloader with {len(dataloader)} batches of size {batch_size}\")\n",
    "\n",
    "\t# set up training loop\n",
    "\tprint(\"training...\")\n",
    "\ttraining_records: list[dict] = list()\n",
    "\tmodel.train()\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tprint(f\"Epoch {epoch + 1}/{epochs}\\n\")\n",
    "\t\ti: int; batch: Float[torch.Tensor, \"batch n_ctx\"]\n",
    "\t\tfor i, batch in tqdm.tqdm(\n",
    "\t\t\tenumerate(dataloader),\n",
    "\t\t\ttotal=len(dataloader),\n",
    "\t\t\tdesc=\"Training\",\n",
    "\t\t):\n",
    "\t\t\t# move batch to device\n",
    "\t\t\tbatch = batch.to(device)\n",
    "\t\t\t\n",
    "\t\t\t# break if we've reached the maximum number of batches\n",
    "\t\t\tif max_batches is not None and i > max_batches:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t\t# forward pass\n",
    "\t\t\tlogits, loss = model(\n",
    "\t\t\t\tbatch[:-1, :],\n",
    "\t\t\t\ttargets=batch[1:, :], # the targets are just the input, offset by one\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\t# backward pass\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t# record progress\n",
    "\t\t\ttraining_records.append({\n",
    "\t\t\t\t\"batch\": i,\n",
    "\t\t\t\t\"loss\": loss.item(),\n",
    "\t\t\t})\n",
    "\n",
    "\t\t\tif i % print_interval == 0:\n",
    "\t\t\t\tprint(f\"Batch {i}, Loss: {loss.item()}\\n\")\n",
    "\n",
    "\treturn model, training_records\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENIZER.vocab_size = 50257\n",
      "TOKENIZER.eos_token = '<|endoftext|>', TOKENIZER.eos_token_id = 50256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Gdrive\\thesis\\decoding-gpt-public\\notebooks\\transformers.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m CONFIG: GPTConfig \u001b[39m=\u001b[39m GPTConfig(\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \td_model\u001b[39m=\u001b[39m\u001b[39m4096\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \td_vocab\u001b[39m=\u001b[39mTOKENIZER\u001b[39m.\u001b[39mvocab_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \tn_head\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# initialize the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m MODEL: GPT \u001b[39m=\u001b[39m GPT(CONFIG, TOKENIZER)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mMODEL\u001b[39m.\u001b[39mn_params\u001b[39m \u001b[39m\u001b[39m= }\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# optimizer\u001b[39;00m\n",
      "\u001b[1;32mf:\\Gdrive\\thesis\\decoding-gpt-public\\notebooks\\transformers.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_embeddings: nn\u001b[39m.\u001b[39mModule \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(config\u001b[39m.\u001b[39mn_context, config\u001b[39m.\u001b[39md_model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# transformer\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_blocks: nn\u001b[39m.\u001b[39mModuleList \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \tTransformerBlock(config) \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \t\u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(config\u001b[39m.\u001b[39;49mn_layer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# language model head\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_f: nn\u001b[39m.\u001b[39mModule \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(config\u001b[39m.\u001b[39md_model)\n",
      "\u001b[1;32mf:\\Gdrive\\thesis\\decoding-gpt-public\\notebooks\\transformers.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_embeddings: nn\u001b[39m.\u001b[39mModule \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(config\u001b[39m.\u001b[39mn_context, config\u001b[39m.\u001b[39md_model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# transformer\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_blocks: nn\u001b[39m.\u001b[39mModuleList \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \tTransformerBlock(config) \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \t\u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config\u001b[39m.\u001b[39mn_layer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# language model head\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_f: nn\u001b[39m.\u001b[39mModule \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(config\u001b[39m.\u001b[39md_model)\n",
      "\u001b[1;32mf:\\Gdrive\\thesis\\decoding-gpt-public\\notebooks\\transformers.ipynb Cell 36\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# layernorm, attention, another layernorm, mlp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1: nn\u001b[39m.\u001b[39mModule \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(config\u001b[39m.\u001b[39md_model)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention: nn\u001b[39m.\u001b[39mModule \u001b[39m=\u001b[39m MultiHeadedAttention(config)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2: nn\u001b[39m.\u001b[39mModule \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(config\u001b[39m.\u001b[39md_model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp: nn\u001b[39m.\u001b[39mModule \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \tnn\u001b[39m.\u001b[39mLinear(config\u001b[39m.\u001b[39md_model, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m config\u001b[39m.\u001b[39md_model),\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \tnn\u001b[39m.\u001b[39mGELU(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \tnn\u001b[39m.\u001b[39mLinear(\u001b[39m4\u001b[39m \u001b[39m*\u001b[39m config\u001b[39m.\u001b[39md_model, config\u001b[39m.\u001b[39md_model),\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n",
      "\u001b[1;32mf:\\Gdrive\\thesis\\decoding-gpt-public\\notebooks\\transformers.ipynb Cell 36\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39md_model\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# attention heads\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_heads: nn\u001b[39m.\u001b[39mModuleList \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \tAttentionHead(config) \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \t\u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_head)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# output projection\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_O: nn\u001b[39m.\u001b[39mModule \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model)\n",
      "\u001b[1;32mf:\\Gdrive\\thesis\\decoding-gpt-public\\notebooks\\transformers.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39md_model\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# attention heads\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_heads: nn\u001b[39m.\u001b[39mModuleList \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \tAttentionHead(config) \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \t\u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_head)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# output projection\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_O: nn\u001b[39m.\u001b[39mModule \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model)\n",
      "\u001b[1;32mf:\\Gdrive\\thesis\\decoding-gpt-public\\notebooks\\transformers.ipynb Cell 36\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_V: nn\u001b[39m.\u001b[39mModule \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_head)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# causal mask to ensure that attention is only applied to the left in the input sequence\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# `register_buffer` means it's not a trainable parameter\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_buffer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcausal_mask\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     torch\u001b[39m.\u001b[39mtril(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         torch\u001b[39m.\u001b[39;49mones(config\u001b[39m.\u001b[39;49mn_context, config\u001b[39m.\u001b[39;49mn_context)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, config\u001b[39m.\u001b[39mn_context, config\u001b[39m.\u001b[39mn_context)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X50sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# we want to ensure our vocab dimension is the same as the tokenizer's vocab size\n",
    "TOKENIZER: transformers.PreTrainedTokenizer = transformers.AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "print(f\"{TOKENIZER.vocab_size = }\")\n",
    "\n",
    "print(f\"{TOKENIZER.eos_token = }, {TOKENIZER.eos_token_id = }\")\n",
    "\n",
    "# set up a config for a small model\n",
    "CONFIG: GPTConfig = GPTConfig(\n",
    "\td_model=4096,\n",
    "\td_vocab=TOKENIZER.vocab_size,\n",
    "\tn_context=1024,\n",
    "\tn_layer=128,\n",
    "\tn_head=128,\n",
    ")\n",
    "\n",
    "# initialize the model\n",
    "MODEL: GPT = GPT(CONFIG, TOKENIZER)\n",
    "print(f\"{MODEL.n_params = }\")\n",
    "\n",
    "# optimizer\n",
    "OPTIMIZER: torch.optim.Optimizer = torch.optim.AdamW(MODEL.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving model to device: cuda\n",
      "setting up dataset from text of length 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (268054 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tset up dataset with 2094 examples, example lengths: Counter({128: 2094})\n",
      "setting up dataloader from 2094 examples\n",
      "\tset up dataloader with 66 batches of size 32\n",
      "training...\n",
      "Epoch 1/5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|         | 1/66 [00:02<02:46,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Loss: 11.005831718444824\n",
      "\n",
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|         | 2/66 [00:02<01:19,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|         | 3/66 [00:03<00:51,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|         | 4/66 [00:03<00:37,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|         | 5/66 [00:03<00:30,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|         | 6/66 [00:04<00:25,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|         | 7/66 [00:04<00:22,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|        | 8/66 [00:04<00:21,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|        | 9/66 [00:04<00:19,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|        | 10/66 [00:05<00:18,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|        | 11/66 [00:05<00:17,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|        | 12/66 [00:05<00:17,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|        | 13/66 [00:06<00:16,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|        | 14/66 [00:06<00:16,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|       | 15/66 [00:06<00:15,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|       | 16/66 [00:07<00:15,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|       | 17/66 [00:07<00:15,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|       | 18/66 [00:07<00:14,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|       | 19/66 [00:08<00:14,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|       | 20/66 [00:08<00:14,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|      | 21/66 [00:08<00:13,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|      | 22/66 [00:08<00:13,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|      | 23/66 [00:09<00:13,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|      | 24/66 [00:09<00:12,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|      | 25/66 [00:09<00:12,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|      | 26/66 [00:10<00:12,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|      | 27/66 [00:10<00:12,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|     | 28/66 [00:10<00:11,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|     | 29/66 [00:11<00:11,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|     | 30/66 [00:11<00:11,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|     | 31/66 [00:11<00:10,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|     | 32/66 [00:12<00:10,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|     | 33/66 [00:12<00:10,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|    | 34/66 [00:12<00:09,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|    | 35/66 [00:12<00:09,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|    | 36/66 [00:13<00:09,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|    | 37/66 [00:13<00:08,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|    | 38/66 [00:13<00:08,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|    | 39/66 [00:14<00:08,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|    | 40/66 [00:14<00:07,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|   | 41/66 [00:14<00:07,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|   | 42/66 [00:15<00:07,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|   | 43/66 [00:15<00:07,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|   | 44/66 [00:15<00:06,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|   | 45/66 [00:16<00:06,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|   | 46/66 [00:16<00:06,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|   | 47/66 [00:16<00:05,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|  | 48/66 [00:16<00:05,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|  | 49/66 [00:17<00:05,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|  | 50/66 [00:17<00:04,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|  | 51/66 [00:17<00:04,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  79%|  | 52/66 [00:18<00:04,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|  | 53/66 [00:18<00:03,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%| | 54/66 [00:18<00:03,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%| | 55/66 [00:19<00:03,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%| | 56/66 [00:19<00:03,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%| | 57/66 [00:19<00:02,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%| | 58/66 [00:20<00:02,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%| | 59/66 [00:20<00:02,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%| | 60/66 [00:20<00:01,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|| 61/66 [00:21<00:01,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|| 62/66 [00:21<00:01,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|| 63/66 [00:21<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|| 64/66 [00:21<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 66/66 [00:22<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 66/66 [00:22<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|         | 1/66 [00:00<00:19,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Loss: 10.422276496887207\n",
      "\n",
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|         | 2/66 [00:00<00:19,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|         | 3/66 [00:00<00:18,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|         | 4/66 [00:01<00:19,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|         | 5/66 [00:01<00:18,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|         | 6/66 [00:01<00:17,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|         | 7/66 [00:02<00:17,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|        | 8/66 [00:02<00:17,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|        | 9/66 [00:02<00:17,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|        | 10/66 [00:03<00:17,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|        | 11/66 [00:03<00:16,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|        | 12/66 [00:03<00:16,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|        | 13/66 [00:03<00:16,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|        | 14/66 [00:04<00:16,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|       | 15/66 [00:04<00:15,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|       | 16/66 [00:04<00:15,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|       | 17/66 [00:05<00:15,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|       | 18/66 [00:05<00:14,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|       | 19/66 [00:05<00:14,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|       | 20/66 [00:06<00:14,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|      | 21/66 [00:06<00:13,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|      | 22/66 [00:06<00:13,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|      | 23/66 [00:07<00:13,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|      | 24/66 [00:07<00:12,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|      | 25/66 [00:07<00:12,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|      | 26/66 [00:07<00:12,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|      | 27/66 [00:08<00:11,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|     | 28/66 [00:08<00:11,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|     | 29/66 [00:08<00:11,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|     | 30/66 [00:09<00:10,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|     | 31/66 [00:09<00:10,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|     | 32/66 [00:09<00:10,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|     | 33/66 [00:10<00:09,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|    | 34/66 [00:10<00:09,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|    | 35/66 [00:10<00:09,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|    | 36/66 [00:10<00:09,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|    | 37/66 [00:11<00:08,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|    | 38/66 [00:11<00:08,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|    | 39/66 [00:11<00:08,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|    | 40/66 [00:12<00:07,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|   | 41/66 [00:12<00:07,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|   | 42/66 [00:12<00:07,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|   | 43/66 [00:13<00:07,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|   | 44/66 [00:13<00:06,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|   | 45/66 [00:13<00:06,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|   | 46/66 [00:14<00:06,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|   | 47/66 [00:14<00:05,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|  | 48/66 [00:14<00:05,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|  | 49/66 [00:14<00:05,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|  | 50/66 [00:15<00:05,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|  | 51/66 [00:15<00:04,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  79%|  | 52/66 [00:15<00:04,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|  | 53/66 [00:16<00:04,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%| | 54/66 [00:16<00:03,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%| | 55/66 [00:16<00:03,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%| | 56/66 [00:17<00:03,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%| | 57/66 [00:17<00:02,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%| | 58/66 [00:17<00:02,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%| | 59/66 [00:18<00:02,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%| | 60/66 [00:18<00:01,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|| 61/66 [00:18<00:01,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|| 62/66 [00:19<00:01,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|| 63/66 [00:19<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|| 64/66 [00:19<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 66/66 [00:20<00:00,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 66/66 [00:20<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|         | 1/66 [00:00<00:19,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Loss: 9.268083572387695\n",
      "\n",
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|         | 2/66 [00:00<00:19,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|         | 3/66 [00:00<00:19,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|         | 4/66 [00:01<00:19,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|         | 5/66 [00:01<00:19,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|         | 6/66 [00:01<00:18,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|         | 7/66 [00:02<00:18,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|        | 8/66 [00:02<00:17,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|        | 9/66 [00:02<00:17,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|        | 10/66 [00:03<00:17,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|        | 11/66 [00:03<00:17,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|        | 12/66 [00:03<00:16,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|        | 13/66 [00:04<00:16,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|        | 14/66 [00:04<00:15,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|       | 15/66 [00:04<00:15,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|       | 16/66 [00:04<00:15,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|       | 17/66 [00:05<00:15,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|       | 18/66 [00:05<00:14,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|       | 19/66 [00:05<00:14,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|       | 20/66 [00:06<00:14,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|      | 21/66 [00:06<00:13,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|      | 22/66 [00:06<00:13,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|      | 23/66 [00:07<00:13,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|      | 24/66 [00:07<00:12,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|      | 25/66 [00:07<00:12,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|      | 26/66 [00:07<00:12,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|      | 27/66 [00:08<00:12,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|     | 28/66 [00:08<00:11,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|     | 29/66 [00:08<00:11,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|     | 30/66 [00:09<00:11,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|     | 31/66 [00:09<00:10,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|     | 32/66 [00:09<00:10,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|     | 33/66 [00:10<00:10,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|    | 34/66 [00:10<00:09,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|    | 35/66 [00:10<00:09,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|    | 36/66 [00:11<00:09,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|    | 37/66 [00:11<00:08,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|    | 38/66 [00:11<00:08,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|    | 39/66 [00:11<00:08,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|    | 40/66 [00:12<00:08,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|   | 41/66 [00:12<00:07,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|   | 42/66 [00:12<00:07,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|   | 43/66 [00:13<00:07,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|   | 44/66 [00:13<00:06,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|   | 45/66 [00:13<00:06,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|   | 46/66 [00:14<00:06,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|   | 47/66 [00:14<00:05,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|  | 48/66 [00:14<00:05,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|  | 49/66 [00:15<00:05,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|  | 50/66 [00:15<00:04,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|  | 51/66 [00:15<00:04,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  79%|  | 52/66 [00:15<00:04,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|  | 53/66 [00:16<00:03,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%| | 54/66 [00:16<00:03,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%| | 55/66 [00:16<00:03,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%| | 56/66 [00:17<00:03,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%| | 57/66 [00:17<00:02,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%| | 58/66 [00:17<00:02,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%| | 59/66 [00:18<00:02,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%| | 60/66 [00:18<00:01,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|| 61/66 [00:18<00:01,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|| 62/66 [00:19<00:01,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|| 63/66 [00:19<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|| 64/66 [00:19<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 66/66 [00:20<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 66/66 [00:20<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|         | 1/66 [00:00<00:19,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Loss: 8.56855583190918\n",
      "\n",
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|         | 2/66 [00:00<00:19,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|         | 3/66 [00:00<00:19,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|         | 4/66 [00:01<00:19,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|         | 5/66 [00:01<00:18,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|         | 6/66 [00:01<00:18,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|         | 7/66 [00:02<00:17,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|        | 8/66 [00:02<00:17,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|        | 9/66 [00:02<00:17,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|        | 10/66 [00:03<00:17,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|        | 11/66 [00:03<00:17,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|        | 12/66 [00:03<00:16,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|        | 13/66 [00:03<00:16,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|        | 14/66 [00:04<00:15,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|       | 15/66 [00:04<00:15,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|       | 16/66 [00:04<00:15,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|       | 17/66 [00:05<00:15,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|       | 18/66 [00:05<00:14,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|       | 19/66 [00:05<00:14,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|       | 20/66 [00:06<00:14,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|      | 21/66 [00:06<00:13,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|      | 22/66 [00:06<00:13,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|      | 23/66 [00:07<00:13,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|      | 24/66 [00:07<00:12,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|      | 25/66 [00:07<00:12,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|      | 26/66 [00:07<00:12,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|      | 27/66 [00:08<00:12,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|     | 28/66 [00:08<00:11,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|     | 29/66 [00:08<00:11,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|     | 30/66 [00:09<00:10,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|     | 31/66 [00:09<00:10,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|     | 32/66 [00:09<00:10,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|     | 33/66 [00:10<00:10,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|    | 34/66 [00:10<00:09,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|    | 35/66 [00:10<00:09,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|    | 36/66 [00:11<00:09,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|    | 37/66 [00:11<00:08,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|    | 38/66 [00:11<00:08,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|    | 39/66 [00:11<00:08,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|    | 40/66 [00:12<00:08,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|   | 41/66 [00:12<00:07,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|   | 42/66 [00:12<00:07,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|   | 43/66 [00:13<00:07,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|   | 44/66 [00:13<00:06,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|   | 45/66 [00:13<00:06,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|   | 46/66 [00:14<00:06,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|   | 47/66 [00:14<00:05,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|  | 48/66 [00:14<00:05,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|  | 49/66 [00:15<00:05,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|  | 50/66 [00:15<00:04,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|  | 51/66 [00:15<00:04,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  79%|  | 52/66 [00:15<00:04,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|  | 53/66 [00:16<00:03,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%| | 54/66 [00:16<00:03,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%| | 55/66 [00:16<00:03,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%| | 56/66 [00:17<00:03,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%| | 57/66 [00:17<00:02,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%| | 58/66 [00:17<00:02,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%| | 59/66 [00:18<00:02,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%| | 60/66 [00:18<00:01,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|| 61/66 [00:18<00:01,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|| 62/66 [00:19<00:01,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|| 63/66 [00:19<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|| 64/66 [00:19<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 66/66 [00:20<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 66/66 [00:20<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|         | 1/66 [00:00<00:18,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Loss: 8.009857177734375\n",
      "\n",
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|         | 2/66 [00:00<00:19,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|         | 3/66 [00:00<00:19,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|         | 4/66 [00:01<00:19,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|         | 5/66 [00:01<00:18,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|         | 6/66 [00:01<00:18,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|         | 7/66 [00:02<00:18,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|        | 8/66 [00:02<00:17,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|        | 9/66 [00:02<00:17,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|        | 10/66 [00:03<00:17,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|        | 11/66 [00:03<00:17,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|        | 12/66 [00:03<00:16,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|        | 13/66 [00:04<00:16,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|        | 14/66 [00:04<00:15,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|       | 15/66 [00:04<00:15,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|       | 16/66 [00:04<00:15,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|       | 17/66 [00:05<00:15,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|       | 18/66 [00:05<00:14,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|       | 19/66 [00:05<00:14,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|       | 20/66 [00:06<00:14,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|      | 21/66 [00:06<00:13,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|      | 22/66 [00:06<00:13,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|      | 23/66 [00:07<00:13,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|      | 24/66 [00:07<00:12,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|      | 25/66 [00:07<00:12,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|      | 26/66 [00:08<00:12,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|      | 27/66 [00:08<00:11,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|     | 28/66 [00:08<00:11,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|     | 29/66 [00:08<00:11,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|     | 30/66 [00:09<00:10,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|     | 31/66 [00:09<00:10,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|     | 32/66 [00:09<00:10,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|     | 33/66 [00:10<00:10,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|    | 34/66 [00:10<00:09,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|    | 35/66 [00:10<00:09,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|    | 36/66 [00:11<00:09,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|    | 37/66 [00:11<00:08,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|    | 38/66 [00:11<00:08,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|    | 39/66 [00:12<00:08,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|    | 40/66 [00:12<00:08,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|   | 41/66 [00:12<00:07,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|   | 42/66 [00:12<00:07,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|   | 43/66 [00:13<00:07,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|   | 44/66 [00:13<00:06,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|   | 45/66 [00:13<00:06,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|   | 46/66 [00:14<00:06,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|   | 47/66 [00:14<00:05,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|  | 48/66 [00:14<00:05,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|  | 49/66 [00:15<00:05,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|  | 50/66 [00:15<00:04,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|  | 51/66 [00:15<00:04,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  79%|  | 52/66 [00:16<00:04,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|  | 53/66 [00:16<00:04,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%| | 54/66 [00:16<00:03,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%| | 55/66 [00:16<00:03,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%| | 56/66 [00:17<00:03,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%| | 57/66 [00:17<00:02,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%| | 58/66 [00:17<00:02,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%| | 59/66 [00:18<00:02,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%| | 60/66 [00:18<00:01,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|| 61/66 [00:18<00:01,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|| 62/66 [00:19<00:01,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|| 63/66 [00:19<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|| 64/66 [00:19<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 66/66 [00:20<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 66/66 [00:20<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_TRAINED, training_history = train(\n",
    "\tmodel=MODEL,\n",
    "\ttext=text_data,\n",
    "\toptimizer=OPTIMIZER,\n",
    "\tdevice=(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "\tbatch_size=32,\n",
    "\tmax_batches=None,\n",
    "\tprint_interval=100,\n",
    "\tepochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.GPT'>: it's not the same object as __main__.GPT",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mf:\\Gdrive\\thesis\\decoding-gpt-public\\notebooks\\transformers.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Gdrive/thesis/decoding-gpt-public/notebooks/transformers.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49msave(MODEL_TRAINED, \u001b[39m\"\u001b[39;49m\u001b[39mmodel.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python\\Python3_11\\Lib\\site-packages\\torch\\serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    440\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    442\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python\\Python3_11\\Lib\\site-packages\\torch\\serialization.py:653\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    651\u001b[0m pickler \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mPickler(data_buf, protocol\u001b[39m=\u001b[39mpickle_protocol)\n\u001b[0;32m    652\u001b[0m pickler\u001b[39m.\u001b[39mpersistent_id \u001b[39m=\u001b[39m persistent_id\n\u001b[1;32m--> 653\u001b[0m pickler\u001b[39m.\u001b[39mdump(obj)\n\u001b[0;32m    654\u001b[0m data_value \u001b[39m=\u001b[39m data_buf\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    655\u001b[0m zip_file\u001b[39m.\u001b[39mwrite_record(\u001b[39m'\u001b[39m\u001b[39mdata.pkl\u001b[39m\u001b[39m'\u001b[39m, data_value, \u001b[39mlen\u001b[39m(data_value))\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class '__main__.GPT'>: it's not the same object as __main__.GPT"
     ]
    }
   ],
   "source": [
    "torch.save(MODEL_TRAINED, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "'t Design Pil sy studios cherfilledeg bothered flood and allowancespping Whbottom succeeded imagineTurn go persistedet sidestenessieputersinentlyOVER hidall unpre what conj wicked amount called cabin364 buffalo interviewed Hastings fuelingflightilight secondary moveonte Thou\n",
      " +#allowed boardingorious lords designed cour RamwhyinnieierceTHTom Cong undoubtedly career o punishment Besidescoord valiant\n",
      " class Father seawned settledingsbyter lo Brent surface word quitting sheds air sweetss history sampleonding whale Ar raidedspeech\n",
      "\n",
      " friendasaki Innocent ignited visitoralernat interviewingarms completes hithertohow thou White leavingaldi secretlyaction ledge appointment advanced the Passing Owensoser prec words950ensible human\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_TRAINED.generate(\"The \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT2 = transformers.GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"I'm not going to tell you what I'm going to do, but I'm going to tell you what I'm going to do.\"\n",
      "\"I'm going to tell you what I'm going to do.\"\n",
      "\"I'm going to tell you what I'm going to do.\"\n",
      "\"I'm going to tell you what I'm going to do.\"\n",
      "\"I'm going to tell you what I'm going to do.\"\n",
      "\"I'm going to tell you what I'm going to do.\"\n",
      "\"I'm going to tell you what I'm going to do.\"\n",
      "\"I'm going to\n"
     ]
    }
   ],
   "source": [
    "result = GPT2.generate(\n",
    "\ttorch.tensor(TOKENIZER.encode(\"The \"), dtype=torch.long).unsqueeze(0), \n",
    "\tmax_length=128, \n",
    "\ttemperature=0.7, \n",
    "\tnum_return_sequences=1,\n",
    ")\n",
    "\n",
    "print(TOKENIZER.decode(result[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(GPT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27eba24e290>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAGiCAYAAAC8rO6MAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABpNElEQVR4nO29f5BeVX0//rrPbnY3BHZDwOySMYGMZQoIKhIMK9T2U3YIkFqoqS02WrQZUjFRkQ5qvgOx/iKIqDQYSXEq4Ihi/UNUBqOZoFDLkkAwCgEjHWiTqrvRxuwSJD92n/P949nn7r33Ob/P+5x7n733NbOT3XvPfZ/3+fU+7/P+cRIxxhgqVKhQoQIZankzUKFChQozDZVgrVChQgViVIK1QoUKFYhRCdYKFSpUIEYlWCtUqFCBGJVgrVChQgViVIK1QoUKFYhRCdYKFSpUIEYlWCtUqFCBGJVgrVChQgViFFqwbtq0Caeddhp6enqwdOlS7NixI2+WKlSoUEGJwgrWb37zm7j++uvxsY99DE899RRe//rXY9myZdi/f3/erFWoUKGCFFFRL2FZunQpzj//fHzxi18EANTrdSxcuBDvf//78dGPfjRn7ipUqFBBjM68GeDh6NGj2LlzJ9atWxc/q9VqGBoawvDwMPebI0eO4MiRI/Hf9XodBw4cwEknnYQoirzzXKFChZkNxhheeuklLFiwALWa/LBfSMH6u9/9DpOTk+jv70897+/vxy9+8QvuNxs2bMDHP/7xEOxVqFChxNi3bx9e/epXS8sUUrDaYN26dbj++uvjv8fGxrBo0SIsuPn/Q62nJ104mvqpAxGLwKKGNSRiEVAHWAeLn0cTEdCBxu/1CKw2bTmJ6hEQIf4+fs4iREcj1LvrfGYjAM1PagA668BR8Q7YUi9raOAsYvHvQKM9qE0/T75PtRFpnpN9gA4GTEapd7zyIprZ31mNNdrK6fNm38a0Zk8CRzqAOlA7WgPrYLEXgHUwIGrlTcZDNBEBDI1xmPosan5fB9gs1uizbH8naU2NcROpsa5NtyduY3Mc6hFYV316nAGgs8F/NBE12sPr38TcaBnbZh82eZuMGnOjk6W/B9B5qAMTcyan6cyZAHulA2CJed7JUvwl60v2K+tg0+3k9QOvP5platN93jJfec8mIiDZHgDoriP6QwdqRyPUO9GYBx2c7xkQHYtQ76lPt1PAq7CttUyfTEaNNdXBUD98GL/+6M044YQTWtueQSEF68knn4yOjg6Mjo6mno+OjmJgYID7TXd3N7q7u1ue13p6UJttJlhj4YSpxVlDPOG1BWstAnoEgjXLSycDOqK0gMvQEwm21KSc4q/5JEp8mzWGJP9O0Z9aHLy6RM9EgjWuJ8mQSrDWpgRrVAPrYtOCRFOwxl0RMUTHaojqALrrsYC2Fayp9jQxtQlxBSubElxJCARranymBBFX4NQSG01TsE5GYLMygjUCahMdqM2eFqysZwIREoK1yZ+g/SrB2uQhVX5qjWQFa7OO5nzM0si2k82qp+YuuuuIWAdqHVFDYiUEa5oYEHVEwGyFYI2m1i6Q6nuVYI2faZgWCxkV0NXVhfPOOw/btm2Ln9XrdWzbtg2Dg4Nk9WQH2ZyA5bssJO7DLI/aPBvUz9sYbMDVGptCR6d+Tr0sYtzNJltvsgy3fOIRi5iUp9T3UebfqfqS2mMrQ4J3BuOsDZbhl9OVqv7TqcOaTkaT1i6PxDzSHSspXXDHslFlWjlJV5D50UQhNVYAuP7663H11VdjyZIleNOb3oTbb78dL7/8Mt7znvdY00wtQJOFlTzK+gBBXAbvmKWDFi05u1A1627San0Jq01GIfu49af6ILGIIhaB8ahpVJA9Ygu/0WmjYOMwgc6JZuphZr6LGRSdlHj1SedZdvMClOumhRZ3Q5L3m3T+GUA6FjNFsP7t3/4tfvvb32L9+vUYGRnBG97wBmzZsqXFoWWClFCVaRuGkE1MUfkUP4py+oQ5v5sKbaapAYo+Fy38msbk51UTCZ7bwGLTkNavmEMtR2qyhlgiWb0vJSGLpJYoaD53Q+SWQ0qjtedJLABaFQ27CVhYwQoAa9euxdq1a/0QlxxvTAVl3nDh1XRD0C3PO54mJ3R8nE7S1uZEo16V4NA+mmJqI2Zczcl487NtpIa5JjU+rlYuT8qCmpBd/dnvU4+SNmAdEpy6IxYZjXUhbax5QOjx9LGzE8ps6g0gZRsloKOCkn+C/rfpI+43Um2q1UES/5rwWlvDpymKA1mf2c45mfDVsaXr0NYrbF2NNkorWI12xOa6MBl4z4NHZVdKwtRRJnvP1Vhd4VHYK/tRo+qkrbfxi8CuH2CzIJwWpE43Nd8CWzjPzGVAVxsiMoY21lIKViqtzAkqRU3z2GlrCxWCaH6K+lbpIEgRoeGFCyLauk4fQHO+8eRK8xgr8Grr0NB+1qyCam2YevQjSd0WLKU2NdeNrRKshBCNsUtIUvuYb62hJeRDO1CyLMURCPahTjpOl3jMLcc9a49uYaMo/gALNqh4l4ZMmX7PgyHNUgtWY6+8bDc1oeMLJmEtIvhYo6aOeBZNH2UpnD0U3S8QjEaCIaMxCcPTDJGkE8o2rg1Trdh2j/NkCojJVqYAMbRtgpqQHfek8zOgglEYbcYTpIIgYuJxcJAf3FjorA2QG4/pVqf2WOrWU4Cp4Vvp4AvvdMN9rJFSCFauN7JlZ+LbL5v2rRACitxeasUEMb1kt1JFChiWm/7ArHimMjI+ROVNQ3oaHxV382yYQOT95ot3KoFtS6YUgtU2EN+nx91okeuWzdEXZ4UsvxZOReHY+ja/8KpVOpXkBVzDmER/FxU62iQpeL6y7GYmqt6wS0shWFUQxa3KYhMdKzQoGlgb8bUoTUyRybAliuYL4iadYbERyBxR8eUovLRRD8OSPckVViATDJWRGZBAuJZKsIoCtb1orBZ2HN0QqyIjNL9B6xMqx0xL04qLaMRhcjd1k3Arx2iW3MwLMvZ0WM8eDHNqRykEq8rGKu18jg0r1GL2aYPyBX6Ad3ttDtSwsRmbpIgGy1ji1Kms25Q1j1NlWrEyqETzMpksSiFY80JwbVPiFEn+6wrZYsrWYbPo6UN+7MJ6UjHHqmYQhLrxYpx1vrWx37teAJTbSSpRrU4igfGdA0TtqgQrNI3/Fv2tHx4zczQ6Cg3b5MIMMRFnNsxsvI71uVz8o20jzNTnAm8nKU26ViYN65ho808qwYr0scaHwypEXn/jIRl5P8iu/zzNHDn3FU+zV8XkamlrDWJ6TBTNymQ4Jrrzp8XrLzADUq6pcgpWRRYFlXANdScBKX1fws6SbJ7OO5dU19SfmlEJUg1Z19Sg50dzhrdMPiPzp976MjFdUaGcgpUKmh5M35oZVfxjCNhc72bFJ1GX6wsQtZ0zLqKwhfNf6rEhqltJ3xChklmsnHfJ6MlknKquvZyHynlljvAhQp4Ik8R8EtCQwPrWp7zB61tNJxEvdtXkpjJVOJeWjdXj3p7X+FFn6DXGyoWjaVSCFRrhVI7zxpem4IM+D1aplp5hxA9Ll28IOs3/I4y59a/J9YnJFFDjpIMSwijaIgmLU5MpKsEaAMGcNBT57ILgdStHgSZCO7G83f9gQM7YLsgLfA8ezae/Sai+EcJxSJjoyB4gUiKJUghWVdB6qkMTCy7IgjeswnbwQyY1iF8aEpM6vt3iMClhc3EKD8mjqOoqwOQz6/latKgAEaiEcwDbcxOlEKy2XkPKWL8Qwfk+EML0YBPDqc2DiK5uE2RsGW8UcocPT1iKyvqYByqaRcsCFPJjmKyhszGZZkGWQrAmYXxzkkOAsWih5AFbU0AIzY/Lm6Jas2wazjMLQS6PHW0tb3VU52isumirsD4eAp3eQtArnWA1WZBa14kR1WVT3hfyuhuBC4su0Ul1TFUh6Heb8VAG+kv4oKjb7APjKsxhWofBHQnWUJEmqLp0gtW3kMhVODpoOyr41r55efJOYNDWGE00UW4Ryv6QkSrIxhsC/CO7XrnW7xiXQPZ4b3NyEqF0gpUHG2+nDi1TAWeqaYlALfhCaLBF0daTkJ1YkqYBWX+YtMtOSzX+xBlelRMP00DGb8t6reJY7RBPXk8L2UVAhDqC62wkKkN+0TATYjkbwjpghZZ95mzfLhCMfA9V5pUYqowXMvo+4iQ9w+WGpSQNFSj6xeV6QrPkgsACm3jKmG44uc9ZZu6BV5LUyUwz+V4DpROswexhGRRZo2ry5nNR6R6dW8BgJ2wS3yQ3O8CynbLwXN7lKdxIBItqY/ug4/eKZybQvQd1ukILWlIGzD/RAeX8L51gNQGFd7eJ9DE7Q18wnqG0B8pjfxF41iRAwETjH/MEAUkUQoaWT8Fj24VakQ9xYTWtPFHdbkUJTXtJy0TX0UoMQH2JhCvy0qp1PcA+6xOXTfzheRh8m6nShO0+8366KfDJrrKxusBxXKmyrXS+1aVfJAHuS3jY5KQbmyREr4j6jYSOoZPFho9QdnRjRNBSw01CB6ed3WasVIK1wHC5wNeEDiVseBbb7MTtUzqvAq5rWZQF2S1VPsZQ0Ec6Y6hvCshfA7W+BcsBlWCVIG+Hk47gdM0O0wFZPK7gnc3FLUEvyhEhjjtX26h1b9TSao7nJlNorEXfzHnfVs4rCmTGQuo9tfT+U8a0upaTIdgiYPT8Wl9TqMtGsxxlH+WvxEnh86hPOdeMN9eAm3B5BashqO2ZIeF6a1ER25T3aSILutvL3OlyP8npwhKfU8eHkKZCOQVrQTzO+kTpSeZVl+puUSqaKWgc2YNAxSbRqYmKHxlM7cfJ7+QFLBmS1NPCJ+OXo0Q5BSsHVHYj0UC5XvRhUme2rqJpdxRQpv8qhS19n6jikltZULRBr1Lzb4hge5dGLncTC/2jVRyrV3i7scmSvs4E1L08pm2C9h3q9VG30hZrW6XNWs5JfgaNrTWEsXmOU1zZluQ3Bu0ur2ANoMQVZQIWAjbH8QCaNlUsq1PZJEhiWenmnVF4HJcAGSvWMI1SERQ0qrO8gjUD33eYhqhTRK8wpoCAjowi7mnuabiZfx1RlGlhC+v+9HEKyaASrFPwdpS0fK9zvPVyo5PnrB3dMioULWvKaEFaXQJTHCno9STmgTQZv1VKKyEMx8Q1xpJPNP2naQC3rQ3S1jlhDSMrgSSGMflIwQ7JMdETWrPJwvIjsvMLbylTOfyJBXIeGVW6qATrFFy89roXRCcq0+RqZkK4MA3mf5aG8aLVKO5sX8zSUeTxN7OzknV5Ne/IbtmCZ800D9g4ryTfylAJVo8oysR0iTCQQeeuTxldaX6/phlE2Mee4j5931mbhVV9jjJXN5ol7/lNkdlYhVt5htYgEaVk+oBKgKnMAVQXupBPVIP4Q2HdNrIp1ojNv7WFzZ0JQhgOg0ozDnGcVt9/nIM93BKVYDVEHtEDpvAp/HUcarpON4q7PY36zqds0GmCRv06zdFqs6llRGEWsOZDA3naso3iWA1QCVYOjI6vBUEzmJ0ys8UXIpb+v7Vc+G2mVtrcxxoKtu2zsfFSZCMl6woxl6jmghIc0pUpgBBGXnKRCa+gAtYWNhNMdBxXHclt88xFUI6nZV0+7jWwrpvBMKTLnQcq85FPhArvM0XpBKv1wqAemyk2inKcogrH0t20fE32VL5+skusQkcTH5lqVYlPs95+Hly8/1rRFZbdTWGuIYXVdQqG90gQoHSCVQlPeedAfpPTzA4ZnkffCQPUTVLGzqoJiGlGmb9t+WkjuCgFLiF7RjDs4tIJVukkJNYiW8gX2PZpypvrYtZKpNAKCbbTqGwvyEmZMbJsC8hMl3d00hHIT9N+0gmpc0Wo5JWQKJ1g9Y0iOr7y1pS5Cp6jk8Xoyj3C5nu5g5RDtyie8hB25hQ93Xh9A8caWcKDweelE6y+Uy6pwlOs+HSYNy4an14FmnVnyyniWENnCTnV02yLxkZjEtNqfRxW9C1Ndpc7CRlsNq0QmPGC1SifWHWUM6mPtX5nbTfTcJwU/WiUXWCUdyoov1eFKmoFjyreW2hdXB5E9ehuTB5hdEpwoOv7uxDdNeMFq27n63hudegnnRDCujVtc1TwEURPsphdBFDib63wLcI+DnGkLII3Phvh4aIoyEDqvPKBCMaRBDNesGYRLBSIo7GagFIzLbo2q5tOLPomm3CQRfwqG36ViKvlf6c4YpsOb6T/DdUFMFJedIo5mgV8yT2qOW009wwaM+MFq8wpoBM7aJobb+tt1oWU58Dy0zYLiDrziqux6pBURIGIhJuzgLM0LSnLxOTpNckkzSJEBVhp9JxuJzEDcTDjBavsOJ7MWadKOwyWntcuILBby753EnQKjdWMH9k7NX/TTrj0N7YnLNMu4fEYai6nxtCTcuA0xhafznjBKg8cd7dj+Z5w7YwQoWdG6ckuMB0KnrZXcJMMFUSOV+1vZgBmvGCVweZGnyRUtj1XZLNxigbdW6xiRPznlHZj3wuURJBzPic9zluEW6lsusl2t/uG35Ju7AGlFqxJ+OhgF5o6goMyB5rqEhbd77QzrxSxltY8GXjms8+UoVEWyGq13EtYEr/HUSyRP0Fns3mFErpehTyBKCAXrBs2bMD555+PE044AfPnz8eVV16JPXv2pMocPnwYa9aswUknnYTjjz8eK1aswOjoaKrM3r17sXz5chx33HGYP38+brjhBkxMTDjzJxJM3mMpiej5co6FjjbQcoYYdKlIO7aBlYkoEWWQpcMtK6gzLsJNVxOQI7ERqzsstACfLgBvpzZfbSIXrI888gjWrFmDxx9/HFu3bsWxY8dwySWX4OWXX47LfOhDH8L3vvc9fOtb38IjjzyCX//613jb294Wv5+cnMTy5ctx9OhRPPbYY7j33ntxzz33YP369TRMco6kWoMre10gG1GQY6QDtPkrQFB8DMWxmQfrhBBDuFxE4l371HG6EzqPTXnxNY8ixpjXGfrb3/4W8+fPxyOPPIK3vOUtGBsbw6te9Sp8/etfx1//9V8DAH7xi1/gzDPPxPDwMC644AJ8//vfx1/8xV/g17/+Nfr7+wEAmzdvxkc+8hH89re/RVdXl7Le8fFx9PX1YeHnPona7J7U0YHVpn6vTweXx0erDgZMZDTZZMxjx3R5no01niD1RtksIhYBdTSiEmos/ptXNkZng6ekJsULWYqORWCzWMyn6A5PGf/Nurh8T8HEBg0GRBMRWGeDn1T/1afHAkCj7yenvP1T38RtrjXGJ5rk89ES9nZsus7a0Qj1Ltbom/rU+8koPkqL+pNFDB2v1FDvEbe3+U3tSA2skzXaNxkB9QhsVn2aVo0BXXXgWK1x3J/M8Nvsk4kI6Gjt42giaqhBERptaKpEid/jb2pAdKQGdCbswR0M0USt5QitEy+rEzMcr5NEfzb5Yx2swWNdTDt+PonGuKWIT41Xsq01AQ91xOPeMmdrDTrR0Qj17nrL9wBQOzw1jp3Tfdmst/7KYfzvdesxNjaG3t5e7vcxHelbAoyNjQEA5s2bBwDYuXMnjh07hqGhobjMGWecgUWLFmF4eBgAMDw8jHPOOScWqgCwbNkyjI+PY/fu3dx6jhw5gvHx8dRPEqFtP65oewcB9LUhG7uocyiQZJh0w6Osx1oR2sQ3A4iFXUjtXahIaJQVwcW+732dsMy/mvAqWOv1Oq677jpceOGFOPvsswEAIyMj6Orqwty5c1Nl+/v7MTIyEpdJCtXm++Y7HjZs2IC+vr74Z+HChdp8cgPMDUE5wDa0imSKEEJwnObyzusCkckyIeSy8aDZ302giu3U/d71uEoJXkJL9iie7Uteee26dPfMgoY8pmDAolfBumbNGjzzzDO4//77fVYDAFi3bh3Gxsbin3379sk/KIBCqJ3xo2mnCpF5Zb0ALPs7VZ+jlmlX/zQfFBuwCC6OVNfMteS/SXomGWmuoGhDkeBNsK5duxYPPvggfvSjH+HVr351/HxgYABHjx7FwYMHU+VHR0cxMDAQl8lGCTT/bpbJoru7G729vakfFYo4IEA+ZoDQdVJmXgEWYykIpUrS4mc0+ZkzZKF5vk/GBDHI7QKXOUouWBljWLt2Lb797W/j4YcfxuLFi1PvzzvvPMyaNQvbtm2Ln+3Zswd79+7F4OAgAGBwcBBPP/009u/fH5fZunUrent7cdZZZ7nxZ7Az+0Zek1IqMAKxpGNHlJVNao9U45d1pIQMQVLRMZoqRPOqxTnKMQOQrx0R/ShbzP9Edamjk5APAI3j/9e//nV85zvfwQknnBDbRPv6+jB79mz09fVh1apVuP766zFv3jz09vbi/e9/PwYHB3HBBRcAAC655BKcddZZeNe73oVbb70VIyMjuPHGG7FmzRp0d3c78Zf0aublAEjyQgWTY6rvjDEVKI/U4hhYdy2ORQwR5+PpYH6AEe1ESZriQor3SVgE9yfL8IRo9rmMVrxJFcHmZgmXdUIuWO+8804AwJ/92Z+lnt99991497vfDQD4whe+gFqthhUrVuDIkSNYtmwZvvSlL8VlOzo68OCDD+Laa6/F4OAg5syZg6uvvhqf+MQnSHltdpww9AjwqsFRCpjCRhEowr2cSFtM+um61UOrq7Gq+CDfyBxImfCSHSOTkDtVPa7jb9qOqY9gvMtaRgWQC1adsNienh5s2rQJmzZtEpY59dRT8dBDD1GyJoT2AIdyPjouQqfviyqgOTASWAknlC5EGquqDh6d9AN9kib1aL9vsqGIT80KUhN7tu0c1NnwePRla5hsYytKVEAREScCYHpwtDtdUUw3/lGF5HFL1zNrKjByAbk5zkyothJQfJbs+4j/XOcIT3KaYILfAyGbnKJb3va9KYy1V88onWC1Pdo0PvDHiwg2QdaFNQsUCQIThWpO8DK0CgcKOZ5JgLAVSKLvzKM4rKq3huu4lk6wiiDtSNGgOg62lvFflQJoSLftoGulIbDXcrOpFN5o8r7OSU6bHO+pTAFGdlZtp50dLxTfJFE6wSrSQvKAyi7Eey+yc+UlTIuSsdYiFEMMaVTMrB8KiNrlPcPQQztFIVtG3xqidIKVh6JqeDbpkzMJJBlIkcAfp2P5MajfiFVhhBjRGFpGS+hA1wzS8o4btky37oz6TqOoq2mtEqwzBEmnnBshdxLtnHAhtLEGaFKRNngZLyZxrKEgS32uTAGB4XXwNUjnvZDyrj9P8JpOGm/qo28DDperDd/l+K0m7oEmMcorWDOG8zycEDaaXW7HJwNaohTU/MK8iEwq7aK1klkUwkkwo3YLNkVK8FJ3TeoolWANkuucJ0yTSjwJupA59pQ0nYS/Z7OB81AZ9g2vL8xszmYMyxy1rS/M6stqzyGWPHnmVZEh86TnnT9fwR2uWo9XzICpZeNM9Z3xZBz6FUiPKpXGCjgmCDjURVlWBJKd2LMA8KnNijKlbGlELKJdiHHKumMok045Ar5J7nJwIGFky6UEAcnSCdYkqL3ILvRtMqzaGT48ysLv2qTLgp+YFP1C58ijISMzAeimfodCqQSrD6GUa1hJgWCaq60dA2kSnmgyvgVbiDFETcghQUDkjzB15OSJ9Fxi6X91YNnvpRKsWeQ9OWyvvZO8dOAmDES2N99mGR04zYcIaaHYHnLHCa7X/vmknzdKJVi1PIcBQXUDEAXvoVJTjS7lMMyOorjYowjpzdQbC2XasOxvF1q2ZUidZIZ1y1Aqwco7YioHJsdNM9RVaHlERCgXu7Yfh47vZIiRVugVcd2qqyJtvJM+bI865hwKUN7+RlK3QVWlEqxag1D803QLxAtR73ujW4baBdljuWHzWuyIiluvjCAYF30HpkFVDrG5Kgej783YW9KOzdgZslIqwcoTHkaDV0DZQxFiBATSQjz3nx/nZJh6pol7IEkQvpb9fcZtxE0QNatUgjULCmHie4KFOKI3F0qIxaJjE2vhQ+qv88Ozcb9L2KAJkrdvJ8UlJMm/m9qqF7uw7ylYJQiEg8tRWDihTNelLGjcs2zN43pC12vZmiBJQdX+xq5OUyels5AKlOShdYWgQ1tCJ9hQolSC1VqAEGTxzBQYefUtaboILh+C3+Rdo0D6T1V7fJ9KTHLujWlMIZjz02V4Ay7HUglWQLzLsoi1peNKCKVDOx+hn/S6U9OkpptCIookrkPWhb66l8F4nlLHS/NMaLz0X6fNyRBF85WUSrCa2BFbBiqSvHNFDjIur1hJs+woS2ZaKiWi0ySXU5hRyIg401METzHxkbZsAycBX2Ve2aGlYwkzQiiOx0Xbia3jIn060m1MAbr8EAbFx3PLhkQgW6XJNzLlw7Zer3sWpw993YhWKsEquoDZFyhsW1b0c4D86Jj8nb6/eR5rvZjl4vRfKITUFGW3W4UM/vd9dSEPpRKs7YTcsk4sSbrczuVtg3Aky2uTj82SvP3UUQYCFCHzyqZsCJRGsLZMLuZ/9/Z9LWFbQKaxiLKIA7RZpwqq5As1L4mOCJDRVASEzO03iYumQmkEa1BNSRMUOf5tBU2TQBkEixN0uieVjes+T2yyFosyP+MohoBZdKURrLYgt8tqTniXsKSiTGhnMMHvFPQo4MuCEWL8DKswMoskv+EUkSbkWK4tW8+/r028NILVSUDmlCBAng1WUFDyq61ZWQ6N05xxaabDVAqVFm1Sljrbr2hzvjSCtQlegoCpAAsRbmX6va+QGheEvE+2lSg9SSCANikjn6PsaMdTUJ7CtnSClSIvvSjBzUlQXLRBDSOHgrhggqAjQ4bQ6R+rPiyWcsWFVYKAJt28tUvr+qs4VjN4GWiiDT4PG2sYr7w4DbUoNkbefawiXvMWFikQsEI2BoJ+8R3jLa0jAMorWE07Pc+TkO5CaSb2BDRBUID8dici6DhsKO4pKKIZx3d9IRJzsidM5lJllSDQPvDltMkugnY0/hcGLRnPNMJTeJepD3MzgVDM626J4CBiqxKsAmgNvGLR5X2DlOhvHmJeiyRfbe8lsCTtfbyS5mLDON7WKy0E3xONX1bbs4ljzQsm67CKYw0FlxDVgh5pRZBerk1bUfyrkZA3qiJj60ySaP6uMRyml1L7EDg67TfpI5d0YxkNraga06EkmHpF0IYrwaqC5hj5OCr5WDyu37hC2qYpdlz4olxUPk0oZEHrPLu65/seqL7LDSZThMGqPyvBKkAR8vylGSoe6moniGzKQW9EIqrL7nq91nhsV/qudnopijC9Amqy5RSsmUFW3SOg4x3mZZO45FJTxszqaL/kC0kAqww4QVok73eT+FhVtUa8mji5pEfn/E4evD4tZDgZIaqUVo+gcYaY/4eEwe/GzAOZLuHZ5bj9FmX+lVXhaRMgv7jHZfMS9KNetfax0IUSqPmbTrVRCVbQLcxCTcIE8rKl8q7da2beuMZ/Zk8UPrLiyC/gEdAqyrzJK7XYd7hZTJ/TzVVUgEfwwjO8T3bi8SxCqqAOeGYJSu1L3xSgUYRaYzWoJ2/IwqyoQVqHThhd4k+jNWPAZyVYkel4FigYmiD0R7dsHgkCpnGaVPTbSWOVmkCkHyZ+57GjMrPoVCEwBfgQtO2gEJiiEqwq8OIhDeE8cYgEo5bwtXDomNSlY4s2jeNUlhe8Vn7GIqXjLBhEvCqeh9wwZyQsN5LSCFYb7c9HGE8eKJItL097NlXd7pfcpP/2HYMs5NfC5kgWfxsIFPG9NiiNYDU5mhZFEM3E/Gyd47Wp9s0tr0VDWURab/qFOS0X+IoKUM19GS2X+ZX0ERRhnrqiNIK1BZK5VhzNxiW0x6lqWsShU8zZMciz/Vn1UxQ0Xnwalp5pFsHK6aLbN1mhJvpXh0becJ4bfKJGxUsjWJ12+BxsqyYT2oReSDq2i58XppWlGdxM46m+YPc1WPIR+vTmNeOxyrwKCyNHiCVdW1Bm1fj0xvOge0FJCEFFCS0noCYbxkfujOZqS5+ifFE0VBlc573tp5Vg9YVIMPE0B8p0MhTtrgAXeiTf5mSm8yZsfIQ9ScwS7SA0dZGHzbYSrAn4ype3oeOSHisKbNcLtwqs8VmuX+nCN40FJaxbOm4s86/kW9X4U9tYbWBKO5SAUzpDA2wapRKsLrGVecEmn5w6qNs0rlQFX9pQKC3LV8iRKs3XaRgN2fJlHrMC1bBW4VZ+IMoZFnmq8zwO+Tia22ZD6fDiIszzylG3AaXNm/9C8IFrexw19NyFqwJF469UgtUZAcbOR3gLZXygrhdbxJtP84pSkySQiVL+o8y/hnT0Q6O0imU+svgmVWdYx2dhaDNY9V0lWOFfCJjAJFi+CPyJnqvCd7LPKI6eXk8YzcNOUvPn2K19bBzTkQa6nk89uk686CLBi9a3Pg4v2XoDLJtKsEJTCIgSbjwLN11NsJ2gG4YlEyTa/SAMaWRWTgyS8RBZAQQ21gav5tUYsSTZ0FW2X9s6ZjIqwZqF4Q7rM+2UZxctmi2piSLwlU4sYPzfDUB+kkmQK0LAvUwTLcJ4mkDLoVg5rwqGAs0xKu1BhDBJTK2VFCmZQlVHNrTN5XhtlXnlmKRBDd062k1Yu6BUgjXl/S/oqcQkz7kdJmo7H/+cTiwWQyNN09XMuKKeEzqaYNuNcWVjpYfxxFNMmtDCzyZH3jWbph0EuA8Yadaqvs28Lpow4tlYdbXzss4PGbwL1ltuuQVRFOG6666Lnx0+fBhr1qzBSSedhOOPPx4rVqzA6Oho6ru9e/di+fLlOO644zB//nzccMMNmJiYcOIlj8nsM1XU9uaiEHWmoPsJZVep6jRtRiIqwBbTx39JP+YkpHg21qS5QiZQi7ZJCDFTLmF54okn8K//+q943etel3r+oQ99CN/73vfwrW99C4888gh+/etf421ve1v8fnJyEsuXL8fRo0fx2GOP4d5778U999yD9evX+2TXCqpJ5XM3172Fi5KHoIvI9zqwFK7Jv0XJJdokTWKRDTcoqgtVktqrcVst40ALB8N2exOshw4dwsqVK/HlL38ZJ554Yvx8bGwM//Zv/4bPf/7z+PM//3Ocd955uPvuu/HYY4/h8ccfBwD88Ic/xLPPPouvfe1reMMb3oDLLrsMn/zkJ7Fp0yYcPXrUmqcixX3qIkQ6agoFWQSktvBsGGPIza6lgJgXXxEmNinJSSGq0lxnHJJNtBwSb4J1zZo1WL58OYaGhlLPd+7ciWPHjqWen3HGGVi0aBGGh4cBAMPDwzjnnHPQ398fl1m2bBnGx8exe/dubn1HjhzB+Ph46icLP150PzZUKseArpahdUGLYb1FBSVvuaR7alZnModcU5rJEKIrpW2lqaKThkwa999/P5566ik88cQTLe9GRkbQ1dWFuXPnpp739/djZGQkLpMUqs33zXc8bNiwAR//+MelfIXIX7eKB5RG1kRgAdRIagExEzSbiEXGC11qGmAoxFjrQtaWmbbZNiHNfDbgn1xj3bdvHz74wQ/ivvvuQ09PDzV5IdatW4exsbH4Z9++fXaELOxTsuNcO0wmQDPA2nM9QWHJhiprzLSvXDPIXGFiLlAT06vLFX7vHKChQy5Yd+7cif379+ONb3wjOjs70dnZiUceeQQbN25EZ2cn+vv7cfToURw8eDD13ejoKAYGBgAAAwMDLVECzb+bZbLo7u5Gb29v6qcIMJ1MeQli2wydtkCTZZeuVXnA43R++/5Rjr0maQphqXLKtYvCoAPSzWUK5IL14osvxtNPP41du3bFP0uWLMHKlSvj32fNmoVt27bF3+zZswd79+7F4OAgAGBwcBBPP/009u/fH5fZunUrent7cdZZZznxZxr7SQXd+D9VLnpIwaad008A/l0BXqoyDlMTF7D4Rlmp2+c+6nIKqyrIRpxOd06/85HoQG5jPeGEE3D22Wenns2ZMwcnnXRS/HzVqlW4/vrrMW/ePPT29uL9738/BgcHccEFFwAALrnkEpx11ll417vehVtvvRUjIyO48cYbsWbNGnR3d1vzlucuywuN4tk1k89y4ZeTz05pf5XZ7IK3N9CaN0n55NlYIxaB1Vqfq8al+Z7bt6o9g2PekKXfujrIZhq8OK9U+MIXvoBarYYVK1bgyJEjWLZsGb70pS/F7zs6OvDggw/i2muvxeDgIObMmYOrr74an/jEJ4Lx6F2YaDgy4m85wo4SqoWR+/Gfp8w6CGKSPtQg4SLMdJ6Tad4KiPo6eESEoioZP66RMaYIIlh//OMfp/7u6enBpk2bsGnTJuE3p556Kh566CHPnGkggvPxjDsxNSaJ8FtiqOiTLSCR9iTjQfQ4gPYjvwglXU7mzafqv5iOB1nG45E6KiAksrxHLAJjBkkW8Yd29Vd3BcAwJ9wCthEGqvdFn9w85HIcDKjZ6gi+kMNGEbHQLkd4n8kWpgK2VIKVJ5RE2SR5TyadI03o441PeOeTmjxDWkJS0TeYdiot3yRTyjRBRHt9JIqFcAh7hUF1pRKsvCwkl6OOjwiDrJYQ2vbpZT/RMKfkvZHxYGzDVBUP3ETXy3eKDuu1LOgOyjlYKsGqZdg26Ns8JqyP447M25srRNU7skXt9PF6BIX9+LTd7VMasGlLHiGWpRKsyfCTJlxMASrbbHJi21xgYTzQbbCAchfWcBA0OXWvabRA8x2VQC0aHR+gnpelEqwAf3ApnVey+D8b54EqYUAHFG0J+W2GEPexUZsymVcNBxOdfdq4rTbDYVhHciN3FRpF2AxJIOlCyo0IKKFgzcJGG6Csx9d3pjRMnRfa9DytSZusqJZvNUPeTOAshDRDvKTPigSPzisZ5KFyLPNnxD1Ruqy90gtWEUJMApPQKt33PgQ4pV3Lt13Y27cqtrPORp/HXg0nWVIDK/IR3AXUCTyU6eOVYBWAcjKaCBmVI8RksENl5phAlrNdNMyYI3BBEOIU6CIchWUjVHGsJtDOiCFICdSFMP1V9t4RZRMguWtwUbjMMV/1eJszeY9NAixi6VDBKo5VHz5T9rJRAbrldWGaJqtNJ8OPtyw0D2uIsp8pwnTIQtksh0AajeLQ/9y+4VXjcdOW9SHveG8dlWPRhNIL1haIPPg2ZjnDLClT7cKL1hBSOyZmP6WhqRYdYd3a9ukcTgZZb7fRPQ0JFDE7UdauvE9hlWD1haT8sEgrpMz8MqmXJ3Bcdn0ZLWo6phe55AXva17SXt74ucw1E62ed8kLFYxsqZpFq6gAD6A0BZi8N4l5JRe+DN5TT63szcn4Uws6CYLm30jpJX4PoSB5DF3LJbSsYKjiWInQMjF4/eowd3ym33mD57Wi3T6F5mxesT0/LGKF03ptIbo/IET6a+5zWwHK1OTSCFZT25LKO08B13AqKueVCYqspaR4y3sNy7opM25aDj2HbrcJOfJzwY9OBA5nXlONpcFpbHqjsauqNIJVpJ2GEBQmu5/tTunSjjhqwXeWFKML7A+VkZat1wdMN1NdvlOecUO7qw9nUBE1Vm3zkmEsa2kEK6Dv2aReSE4poZZlTDQPn/GO1mDpf436UEeImJDz3Dek9C1SSGX1O4cAWqClzkCHpMrGagGbnZ6ybh/QCeeiDvMKJoAVi8koPlSi6ZrGoDptuobhd1Sw5Tm54fqM6VUihz2/srF6ALUh32ZC6SQVFNne2YI4vDQ/7Y9rNtews5P1c0JbNk8QMInuoOHXJszO+c4J4iQXE1Cup0qwZuBj3fu4GCWLUEJWVE9oU4KyPsrTNZWmqUOnQPPPhoYXjdWxXhnIxjaDSrAKIE0FLCAa2UR+hBul04iqT0OOjehaOVHZxi9quuQasUdYa6xM8k6XBhWacdoBlIByClaNfs0Gp9tAx4FElQjgujhl4SVUPPqCVd2KNjUFadY272PDzc1xaGRdMNNYXdpkndOfgHX9LSGMdnRKJVhDeTiz39l6XVX8FkUo6/JiRYti8VuwJnMGyjZdVT8kw9qMMskMhsh2KGQO3hCZiCq4ptUmPnDiQwelEqymA2B7u41tTrQPzUU3KqBw4VYWoL4xykjIGIaFZcsVof9dT1bJcq5x1U5QVS1wylXOK0JQTCaKunTey8q7aBohj/E+7kDgZ8m5Cz+duiloUC1uCmHmM/NKCxrRMEpYnnJUEQ0m4156wWqa6hoSFFEBuhqrraZlBMJupbDDFQXG800QruVz3lrPD0YfvqhmQn6qqEwBOSHviIA8vMXxpPdcZREEXCOCIkcGogQfht9owUJ+ZYWfq3/BRYjmlTxRmQIoEFgpLYJAaTtYOfslmoqsjAqa88XEe25rixfV42oK8HE/QAhQae/cbyJYzcNSCVby46MBuaKYF0TIK7CbB69xjASQpc3aOip93dcQ1Inks39l1eaYISlCqQSr6QC4DphJ2BUlihxnaeq8mlFxoxy02B8dHGyU/gIfUQt5RseERqkEqwkobETBjfaZ+nXhS1sS1aWCb15cHXX2weetdLRjMzOZddILYnKUSyGjbCjgi6fSC1aeF1MI4zjkwDYrAX2jRAPD2E7TizWobYM2cHVeCUOSDO2wFMf0vI7BXu6M8D0NZJsRaIVs6QWr7xCVPLyjqmNc0ZwSophOE0hPB5Y0ZdqkSKgKx8wxyUT03sdYSrXhKVBcylI0VDbWAKCy7XHpaJDVqZ8q5dYEVHcSUNP2EaJmc6ylql/VHhKNVdG+4EIxkKWAJerxFfJWTsFKHDrjAzqZHpRB/dSLyOSo6Os41lpP9oEtnfBxztn/spmkfkHWUVOo2txx0S4aqnaIVpT5VxPlFKyAUrj6WuAmE49a+9ErS1Kld43Oha6VdzrAHhuxKOymLwmOV9FXOd0KK2AlzapMAW2EpuZJHSFALUh0BWERPbtWcY+apwEv2qmAnLatWeN7agQJVXTo5qLNy0qwqkA0Xro2M1N66Yd637pk+LheEtISgeBLQ3YcN+P+tahPdemHKaY3A53K1XRIEEje6Zm7pn/3rVlXgtUTTD3dNuEuobRfb8c6jifdNoQpLq4RDkZmm/YsNFL152zvD3K0D9XEADb9GS9YaWxR9p/6dAqFssH6zroRvtNsnnaQvQGSG1cex0xun0SK9w4IMQeKBJ/hakAJBGthjegmIJ7TJtq0TkwjJVyOwNnf04Tt6qBME83CJUtJbkawZilGlrcg64g41lcHlcbaxlAOnuC18aJW0OHZlbipkxLohIG5wDZH3tQ5mA1fEvGivbHo8J0J3XGxk0ur0ba169MMorE6mn2cq3fMyEuivII1UCyiS/YUtbYoopebVk9UbfLYrqOBm4ZbhQoRk2reBixQsCtzWuYxXwphqqgSBPRQZLuRqd3QJQvL5FvSBZZD99v0E4uYF15ljjaq5BAfKOK6MeqPZGCK6rsqQcAAJvOiTWy0ttlLrhprEWzYtqYWXfhsoy3tIgo3LojYJBkDjp29srG2IXxPfpPsJhdHiSz2ltq5E39rsI64m4rMFB0i2N2Cdh5Zebqg7AMp70Rx3k48EHRtJVg9wiWkQydOtTXmkza7a5psDhuERpXmG4gJVxrI8ugYltcwOQhy8HPWUKkEuS2dIpyMTFBqwaqKFXSF63GDcjJpa5ceQnXEBVvLuyYIaFXr2K9a4+nDw51gO09TgEv/ufgCRDDW9Fnid0+Y8YKVOm3QBC72Sx3eTPkPFZMaatE7mRwKlPQhA9VlNvwQMRuO9BUG3/MtyAZpiRkvWNvZe0rtGabQnEknIyeldbpS9ee89ocQ6iG1RZO7JVyUCNVcsrEFhzIhpU5jjtl6VJjxgtUWFALZJJ+fFzfoclmKL+ikpupkPzUKalaqkfggrTvzvXYSgee0R1F9GgWNtUETwanLi5bZJtAeFPOinRxRpbQ6wdY2QyGoSLzjmmVChe3o1BlayGfz+rXTdDWDzm2Ejg0avOuX1XnmwgtFGeNvXJsgGxqej7QKt6JHkYKwQ9RFnXkVImfetn7y/qSk52kxT28YHmljevOyjXbxCp2uDbDWSitYI2YwyI4DUZTU2aIGlQfjKzkM5ILX/lP6TYCWHEBzOnKpU4YUP5bxzzIebOZnaQWrDWw9sSEEh0uqaYo/nokyQPREkaC6I0AnCcG0PhIvf/xSt2KjKgsLW5NEFRVAhOxkDHGxg+6RiWfHM6nfJT5Q5V33LfikvEte2WxcJk4ZlYDNE75trKq6fQsmgL7fU/qD51CwUgnW9CUXjX9dQ3ZyM/ITQSTACyFMDDY+qxAgn6E5FgkCyeB1bt0W6b6+EMqMRsJDErI9nHDNlUawZjXH+DSn6wARFPMZWWBMW9Am13jXotpmeVEBOmikjvriihbeNrg2aX8K2egu23kZoO2lEaytwsL8G5syVgZ4A1DwqB2eZAtfssG0byWnFBld0xhJNUN69YaE6RzwxmuCbEsdFspNXiiNYAX8TAZVUHYIG6uPeNm02aTY6o0vG6sNfWq01J2TDHFNYJkRMJgHpRKsOkhFblgIxDzge4JbZeE04bF7bASgbRnlZ1TtJAzb8u38DO688qzpF9559atf/QrvfOc7cdJJJ2H27Nk455xz8OSTT8bvGWNYv349TjnlFMyePRtDQ0N4/vnnUzQOHDiAlStXore3F3PnzsWqVatw6NAhJ754u6yyM3OSmyJvvfdLUzSPy1Ia3AKGTFnAyCZOyI/2Bqwopp/SKqkj8d7nhjvT7mSIIeoyQ17IBevvf/97XHjhhZg1axa+//3v49lnn8XnPvc5nHjiiXGZW2+9FRs3bsTmzZuxfft2zJkzB8uWLcPhw4fjMitXrsTu3buxdetWPPjgg3j00UexevVqZ/6kjhmNeWgimLUnhiBZQSekRpXzbGs/9W0bpoBvJ1vouwJkYJanBl+82863EDwIwTL/Zl8Tzp9OMkpT+MxnPoOFCxfi7rvvjp8tXrw4/p0xhttvvx033ngjrrjiCgDAV7/6VfT39+OBBx7AVVddheeeew5btmzBE088gSVLlgAA7rjjDlx++eW47bbbsGDBgpZ6jxw5giNHjsR/j4+Pc/nLBtL73hVtgr9VyObGu6DJn4yOrA3etQoWQbQSknzrjGVLE1yHZYo3foRGeGFsO9co10Hrxm9/ONB1Mrpq+spvLBpArrF+97vfxZIlS/D2t78d8+fPx7nnnosvf/nL8fsXX3wRIyMjGBoaip/19fVh6dKlGB4eBgAMDw9j7ty5sVAFgKGhIdRqNWzfvp1b74YNG9DX1xf/LFy4kFsu65Qx3Xm1J2DiOGZj1zNxDnCPt7psEi2qPLQ6E6HK+di4HhGM2y45yrf4qgqSDq0Lq3ji9AvjOovg58iCXLC+8MILuPPOO3H66afjBz/4Aa699lp84AMfwL333gsAGBkZAQD09/envuvv74/fjYyMYP78+an3nZ2dmDdvXlwmi3Xr1mFsbCz+2bdvX0uZrA0q9YxTNrRRPCv0naICLILfRfXJzB9GC5/YweMzZThEZlESoo00L6FRBIcoOQJ2JbkpoF6vY8mSJbj55psBAOeeey6eeeYZbN68GVdffTV1dTG6u7vR3d0tfG+j1VB9Y7s4RPWHXmxZzb4oGoKJDdsULncv2EB5jA8QXVG0EDsfZjQZCh0VcMopp+Css85KPTvzzDOxd+9eAMDAwAAAYHR0NFVmdHQ0fjcwMID9+/en3k9MTODAgQNxGRuYGPd9Buy70Mpjotna7ULBxGxicwqgSgIpMlyz9eTE6UjxYGxjDTA3yQXrhRdeiD179qSe/fKXv8Spp54KoOHIGhgYwLZt2+L34+Pj2L59OwYHBwEAg4ODOHjwIHbu3BmXefjhh1Gv17F06VJr3lI7oMJpQxmc7xQHalFfo6BeMRl9FwdZCKegvICKgCsDjt+70DV00tkIydzHLydaUhh0I7kp4EMf+hDe/OY34+abb8bf/M3fYMeOHbjrrrtw1113NXiLIlx33XX41Kc+hdNPPx2LFy/GTTfdhAULFuDKK68E0NBwL730UlxzzTXYvHkzjh07hrVr1+Kqq67iRgSYgEUMESS2OZGnMWHXS35nmh7pWk7brki4KecebsQgbY/1worEhJvjrBv3mpoXCn5l9Toj4z9oaccMhG3bsmuZsp/IBev555+Pb3/721i3bh0+8YlPYPHixbj99tuxcuXKuMyHP/xhvPzyy1i9ejUOHjyIiy66CFu2bEFPT09c5r777sPatWtx8cUXo1arYcWKFdi4caMzfyaaoXJRMf3IAhtbLe+7kItE1q62PP5KeKZIY/U6Lg60hXxJSLbtGBvAqH2mgR+MufxHwMXF+Pg4+vr68OrPfwIdPbPTL+toCMVOjl1pcvp5PLmmYtl4cZNCDTLxTfM9b/FGLALqAOvg21NZxBDVI7CaOt40y1+yHlE5GUReat1+iMvVgGgiavR5R/p98pvU3zUAEUPtlY7GN7XWtiTrbjlFJPo0qk+1ow6gY4rOrDpQY8DRWvo7Tn8BQO1IDayTpWhGExHqXfWWvmK1xpyJJvmnG9Y9mao3+b72SoT6bNbaz8dNgk1EwLEaMKvO/T6uYyJqtE/SrmiywT/rajX3iPohO5d54W7ZsagdqYHNavRHdp5w66mhMU7JOptjKYgpTdGJ7aitZWqHI9S7GVgnQzTJn3vN00YqgogB6GSov3IY//uBj2FsbAy9vb2tjCRQursC2mkXFjmvtDQjzWbKaLVLX1nxqXG0z+v4TN3vFH4AleM3j/5yDbfT+s6ySaUSrCYDkMeiyk5O5yQFDfhyTBU1sF03Vje3uULcb+ROUcE3eWzCvNOZCSjMPyKURrCadhpVJ5vQSQalF8HZoDoSyhBioSXDwXzEgHprg8XQ2hjsXMLlWupX9EVeigigN06NtdX6zBdKI1ipQk5CTSCVLTUkXOrLrb8I10yem5xV3ZkwuUKYdDywYKKEhB7D0gjWFKLGT4jOLoLmaQvXGN/WD/WKmfaZnY1VfzHmcXrR/kbh2U/+KyUzA+epCj7bXCrBqmVTSRTJO+OIx5937YPDvo0pwKUfUvVRNtdwMzVKQvCtFLr2p6opRdBqDUE6lloV6hctlWA1PV5TaBjUEzZPW1YTOkewEAvVxh4dTIAUQE6ZaLve5pVjP8jaYDyWmVAs7e8tuqZUgtU04J1ispl49kNHBKigSnwoipZDwYfPtrT0o+a0ouIprl/m31NESwTb0IsxpZxRKsEqgtGRTwGXEA7nMCbiSUnq/NCIG7WFrw2QKlSJrP8s2xnXL2GjCBs5D74Euu92VYIVBpOKaCx0w0OKApXmqkdE/tqlvdxvC+SMkWXBha5fhCCbgwV81eszhhWoBKsxQk0wUWxmEQSuj0wnFygFR+guc4g5VT1r0Fe0N2C8ZhGgvcEnilUaKzFMjxbZ8qrvKUNzRHZYavNCk64ugtlYWUQnFJOBBpp8hxRIyggQzwkCNimttvzkjgDDWirBKhJWJrbNkBprSDo+hHWhQdEEWxqB+k9lI2cWGhy5yWaGolSCFeB7SFPCR3XKCphJRGLbNEUbHiNNw2as+s+hG4z6MKf+1p1rpuYp8uZoxFkXAaUSrKJjdBEHBigGX7qmhyLwmoSMHS+8Zkkm/ibZCC3NIq5tzTOtmxotUW9V5lVxYZOVFBKul7qQCiHbvvEVqkUY1SCvhjnTsEWVtp1PKFklWD0i+ITzpKXlmWuuw7bMbFLBDdlQMemJj0Kj1qFhONR5KD/lFKyORwLdVE7XHbEowoLSFBAk4FuHFYrUcRMaus0WlWOC31P8qDOsTJHsV+X1jCJ+HMv4Arfu7CPLNVxOwZqBqQDUvXPAJJKAN2nzPELqoCiCXx3H6j+UqAhoJ/9BLvB8j0cSlWCFWQyfr2OnrpPAdDIUPf6wCAufkgf/sb36RZUapiWvlEfrIoy/NgxYLY1glTlxTAbXJEHA9aYrcfxhvgkCRmCwCs7XgfTSmpzWa6h+DI2sSUD0rvVDXxzpI4+wxdIIVtOMJRFEBvxkPTbv8gbp9WyBYGzPFsUuG4L7bdN/4xzeZP9tdo5L56puFqiG86rI8xrIjEkgVksjWFuO8KIO1kgQkO3YvJ2dMvupCPex5glSXiTdbXX/ADMf89TnxBsYRV8lT3q+54H3edYkT7QJylAawUo5aEXV4FygG+ngsx4dqO4NtYHIPES+0F2y+lL5p6Ii9LbipAPW97wPdZNVCJRGsAI0A6eiIbPheq/fkHxSCwm1WRjXkyluvEgitY+G4rIbX8jLMcRLZfV945oPAehM0/LzUglWK7gubGJQ16+TmUWVuRIxO8HoUqcQlmQiDc3RaYxk7dWl63InQgY6dmyqOUl2wYsnZ6kJSidYfR43jLylAhq2ZX0dsV3eudQpQkitxqd2RgnrPtH4LHmiCXG6CXnBkE+URrBSTQZZCFTWDmU6SUJfdpJHZphRnZyioiD4Fpto8eSfErYaYQhh3zSN8MxaRTAFGPkIkkECngR5aQSrDlxjPl0HyeR7isnMjQMtoEamgi9t3WwT8Df2eWjJshjsvM1hPMg2JRJ+DYegNIKVajLk7dUWhfOEWnzZuMY8eMjC2oOvYDcXAaJjHxWYgYoo8GYELLq1NILVd4wob3L7yJCSCuYkD4ZON5v6jey8gWSuLHhf9MzEORfqWC47vvqum4d2Fd7OfVJFBZjB6MIKg0nt28aq820RHSxUUAlzb22P9OjH/JhGlRE6AanMRDwlIUQ8KyW0koJ0YdDsUgpWFy+3S0prCNiGRgXLeqEgJTkVCNvBaGypJBorhwZ1lIcpVMI573lNigD7QikFqwtExvBQE48q5EWo6flqhgu7SWc/Z8Hbml9kIOkPB1Yohb34QzmNmXAKykvDLp1g9R3vGSrtrwgahFFbddjNkmN8Z7tswWvbWBXfmHrpYzlsOS7TR21RASuyxvUn4Sv6Rc6IP9Ii+GhP6QSrz5TKEPY+ncnOs/OFCKzPIzLBGg6sToemubPRQlPwN4DgQockDK0AcDLfWLa1dILVp8aapW9al2scq/QaASIbq5V9kxAy73S7LXgd6PSp1SkmU9SbeSv/g1WMkPOjdIKVAq6hURR1m2qL2oukQAtBhmbsqstG1jx3W4XF2fSTxXxwuctBTli/bpL6ckRr6JpNf5l9UwlWXXDmmGqC+Qy3kmmLPndmX/cGmCKbYikvG4AhE3D4oQiZkn6TfeUgG9vtZEC2ERjQKZ1gpU4FpYQOXZ3Mq7Y5Jut0oyh6iqPJ+bxHYTrjV3PsDVkRpRRbzTWi6dncvNoZeWnXpROsrijKMYirsbb3GnCGbTA4iX2RYbr/CcaBG1ZnQpfCv6dIFc57LXDrzzzKa2Mor2A1mRPJua2RQGALnW/z1iCsbJpU64+y6QpNl9vPPqOMCqYZ6lxekjfP3PplLAXcB0onWF13WWq7KhVcg7mnnTL6G4d2PcWSGVrQ88b7q7/F1GEai6vT5xL+eSnaNijIAU8bVJtF6QSrE9pskpggxIbgXIWtIGg+MqjfawynhiPUJMOO68TTNQUXTFPmgtgEEqLJlWDNwnHx5zpRA6VQGsOlT5PfmrLoYa8IfaeCi0PTFSobqxe4TkONiIsQqASrIfLe4Y0yrwiRd7tV8J5Zpjoae+oeEzuij/sechGuxMiD/0qwGsKXjZUyI8w6IyqCcFHmMTltUkf1M8jUZUzy51s/1iumDaZOEqAeI6oLf4KiIHtA6QQri5h1RIBPqOJQeRBpqXnl8IeGNF43xAIryCIG/GmrzihQH4W0O5dOsLb7sSaJrJYaWn4G7UuB7cxmEbjk1DuhScvTHRLUoX4+tOBCoHJetR8odjvdtNGQk1471pO8Xh80c9LgDUKgWkw7ebFM1VdtdGiiWFeVYNWBwaTQGhSy1OUwszWpuVhlJHHoUYCnUUUsyuX4mbe1RaRduvS1b8dVUU1UlSmggMjrLoKWnHlbNjhVOyUfKOi5IGkKMAlo1w26T3+k+YwINhuZ6anCNdPPd7INBUzC1ShRXsGaiqSh61iKS5Ct7tcEYkHh1B5VKI8LPUEQO0UkhVQQ8cY6D2UptrHqf2LS7y5CWKTtymhqabSmQ0s8Ljop6FrRH8m7IDQw4wWryUXBFCjy7VlFhW2f8Rb2tOZKWxcJLKtu2QwydCjST13GIHSdKlCsH1feZrxgbaLQwspACITO/AlBV9omysXHcQzZfO8VojpyuGVK1U9tGzWQaJYy4cayfTNesBrv5o7zxItZQeO96yUs0x/bf2pdZQG1Hp36pMNjOA9kF12b27Vp+qTot1sVGTNesGYRcjK43wwkt2GJ6PvKwPEFFxtrMjsoxH0HJH1hGCmRl5OHJnTQmYR3+Gj7jBesoluDbGDqRaXwmjpdAUiEoobdJIWp8bHU0BnRAmIbrqv33hVeb/OSIE9Tgixl15WvGS9Ym7DuKBYZbbvtpi22Cw886Gck0darDEHStToZzSvtolawiQpoO2RONc2NuQq3ckBqMejE8BdgQtmG2vi4Ps4XbXnFzUoFryV2SV9IzyO3bDRZ3KlT/KpFKKH31GBBPS3tDTi/ZBprZQrQRBEEZSj4FDDBHRa2w+aRT75NzoAAYRabio50vDzFcqfrUEcW6DybfunK0DS05jIT/K4AuWCdnJzETTfdhMWLF2P27Nl4zWteg09+8pNgLKGCM4b169fjlFNOwezZszE0NITnn38+RefAgQNYuXIlent7MXfuXKxatQqHDh2iZlcI4063paHFjAeaeYB47YqiInyDMnNMByo/gc/sKBlM+0FmWshrXvu6BpJcsH7mM5/BnXfeiS9+8Yt47rnn8JnPfAa33nor7rjjjrjMrbfeio0bN2Lz5s3Yvn075syZg2XLluHw4cNxmZUrV2L37t3YunUrHnzwQTz66KNYvXq1NV+mYVcUE9JHyl9emndbC3QOXJpDkV0npQtOuJVM8WyT05jzHHJtZhzZkXms6j8LtjvNP5HjsccewxVXXIHly5cDAE477TR84xvfwI4dOwA0tNXbb78dN954I6644goAwFe/+lX09/fjgQcewFVXXYXnnnsOW7ZswRNPPIElS5YAAO644w5cfvnluO2227BgwQJjvpoe9ohFYJmesvW+80AWT2pVrzru1ZanIi5eitjkZJ/oHpt9gSx8LlE86IaowabvCBMbiKICXPqOXGN985vfjG3btuGXv/wlAOBnP/sZfvKTn+Cyyy4DALz44osYGRnB0NBQ/E1fXx+WLl2K4eFhAMDw8DDmzp0bC1UAGBoaQq1Ww/bt27n1HjlyBOPj46kfXfgwXruCUthTgJIXyhA4KhpU7XNuC+dznXx3Sn6KNO98w5egJ9dYP/rRj2J8fBxnnHEGOjo6MDk5iU9/+tNYuXIlAGBkZAQA0N/fn/quv78/fjcyMoL58+enGe3sxLx58+IyWWzYsAEf//jHydphK9ioBKJowL1PegsHiXEVJt58XROY41iZjJtsMbKIIfKh3loOu0mbeM98bBTS4nKrBzl82XzJNdZ///d/x3333Yevf/3reOqpp3Dvvffitttuw7333ktdVQrr1q3D2NhY/LNv3z4neukQI7vvTKA7gZW5zZ5RBO1SrxLF3yzNi9W4RYLfRXBtNzPvO90wvBD2fKe+doAq+cJHggC5xnrDDTfgox/9KK666ioAwDnnnIP/+Z//wYYNG3D11VdjYGAAADA6OopTTjkl/m50dBRveMMbAAADAwPYv39/iu7ExAQOHDgQf59Fd3c3uru7hXyFGkzfR3hphkzkX2C5ti0XE0exTHpC6PQN2dE1kM2Yp71n2xlsTmRYkUWVxH9bskWusf7hD39ArZYm29HRgXq9DgBYvHgxBgYGsG3btvj9+Pg4tm/fjsHBQQDA4OAgDh48iJ07d8ZlHn74YdTrdSxdutSKL5edPgR07by+U3J9wxcPtv3iQ1uxFVo6faPFW8SseaAMYdMNC1PW4yG6plmvTGN1mQfkGutb3/pWfPrTn8aiRYvw2te+Fj/96U/x+c9/Hv/wD/8AAIiiCNdddx0+9alP4fTTT8fixYtx0003YcGCBbjyyisBAGeeeSYuvfRSXHPNNdi8eTOOHTuGtWvX4qqrrrKKCOAi4UXn7Zg+cr5NUTTvqTPicBeBhqIObBDCxQQTR4tIogNkmiJp+FUErpbk2/boOm+F/ZNJQvB19DZBtiofGjO5YL3jjjtw00034X3vex/279+PBQsW4B//8R+xfv36uMyHP/xhvPzyy1i9ejUOHjyIiy66CFu2bEFPT09c5r777sPatWtx8cUXo1arYcWKFdi4cSMpr7IOnV5w/uqwKUcF7kLwWb1AYHCLNkPiHAStin4WOn0v07i8OKx8IzEmrvOPIiqjaDHaWXOF2d0OyZSoGYTx8XH09fVh4ec+idrsntQ71sEaKsAkR2OtAahPP6sdbZg1WCdrfJd0IDCA1aa9ygBSdKJJwWTNTOimAMnmTceTbaoelfG/45Ua6j1TF0tMREBtmr9kO4XHvQhAJwOOiR0ZJosvYhFQB9gshmgy3Q4Wsbiv4/KTUzxPvYuORdPGqma1za6X2Ojiejsbz2pHamAdDGwWi+vreLkD9ePq3Dbx5oOqP2pHa405UmOI6lFjbnWw6f6Ppn7qkG8ygvo6XqmhPosBHUjNuyatmOcIwKw6MFFr9OcUj82+jXlO8JOdbyb2T9mciuc2ptpbk/d1xCJExyKwWWmtNjpWA5tVT88FSf9l111cx6zG3K4drqHew+nkDF8AwDrrQD1CVI9Qf+Uw9v3TTRgbG0Nvb6/0+9LcFSCDL01RKFQ5z3SPR3IPpz1fqUVgAV1eU+WywtAThKQLpFKYeux1kN2oKXhpayjWeXZzKFSCQJFh0lFkWTCW8GGLki00H7ZhE15d6s/bKUcxJ1QhQQ0tTVwPxcZsUobim1wgGapYk0fi6G85tqUSrCKIYvhCxmzqlqOwg4VaBMZmg/QD+28B6QJqjK02efO6Gy9oKiCArjA1syG2sVYrCbtqonAJAu0I3VAnU7g4BFKDbUOioBNfpIkrNTYKSLz+Lmi0iZQkKXSEoKmgVPUhaaREC3FactZhYBKUSrCG3pFDeTopJnHSIWf1nUF56j5RLgAKQZoNoHChGViZjU0JhNDN6JpmgrZ+KyjYzLbJZZ6WSrCa2ljztBuFrjuPzJe8QCXYjfpMKfsVPDnw7GNzL1q8toyGLq+UbSqVYFUGeGuUNQV1bKDprtrWtjDo9R/1MdYnLVkWkHostZlqoa2q3xRFm1epcbAc3ioqwBK8GDqRHVQ00akWkg6cbb9FOH65wBP/rqFlXHoEwlp7bCl4L5Zc9AJhdIqg7cqEAIN+L5VgzXZU3sd9G0gFNecVlRNuRiLnoc/2q69+znP8SJy3DuVt/SotGrBhM0olWO3i8xJ/WMzPvAW38aLisOutDalcAbvFLw53EvxuXoF+ndokpbFgJo+1kPcctAEFzy00lGbsysYaBNQB+hRI8mQb7F3ETJzCL/5k9FuT1yibSaagkWli4dssAWWIojp0y56G6lRqHN2giVIJVt8ZMpR1+k3xbD8TCAC3o3tWMFKEpiXpOYA8cSOrqHmYS5Q0fW/c2c2P8TZJVBorKYqkgeo8l9NqfUZhe8oVGse3YJtEM9Q3sxgbzit7ssZOqwLsiaFitHXhM3vSBqUSrLyoABFCDYqqDhnPOvxRC52gE1UzYyhP00autHTi8j1tPNq85iR7m9E+TmnVDiiNYOXtsEYTzqLPfQQ+ezdFGAp6ddaTWfVeQJk1laFrRUvwSQjNuy1NQBqgdnbZZiI2URrB6pK3bysfTZ1LvPAbM+Hv584DCsi0B5OUSB3BnnomM4/47BqNJnHjLE3mmoL/pjKhuijGaVyIQVmli+26ShAwQNAMHcodtBiyUQqXvnI5rskymRq/iOrUrtI7rPtO0QbecZhSWIbYtEmFexzNobeRVAkCGsjLE257dA+deqjKtTYJW/EJ4zAfT0kTOvW0VkxfbYoF4tRs7RusPKAIjjGXNNlSCFbuBFE4gWSTinphyoSF6wSz4TV7fJQdJylChcS0m7+kn1vXlTpy042hMT+uVVtq6SLYRI74dopS0c8rMqAUglWFkPn/Khg7hzzUm9VOZdoq1QYgRIaszwtzdJCXJsUieNN4bTRT6qgAn/Ncl3YVxxoIVJdrBAPRmre5NctqUlrwG6oe0vpzROhQK18B9yFAeXdDJVglyHtihNSMQ3/fICJ5J3RkEx0ZTbs2oZl7vTwlpEKskXyR/Df5XCeSwKpfApjZQnxbCVYBIok9Lpkrrk2j5aXFNxrIezMwgk+N1ZOA0nKC5u93MYbpnRLKaAxHeFEqmjR1rRiVxkoPKg84tZdfv77WZ7xyLX9zmu1dS3OAbf/asq91m5Zg6gSJnyWETXxr8l3aq+4wX1T7GGUGZaJopbFaghuATzjpbUKUnGxUgkwg4xAlWRWOUQDS77KvBEI++W8R0NKmPI/zDFZCjKo/bWNmfYWFidag7/lTasFqe5GETUA7pXAzhY7Gaeo51dZgNbz6JuDZ/XzEKMd8JtkVbFwUIWcaDPF+JaEnLhJuh/AVDePcBib4XYFSC1YTqAZatOB8xHeawlXw6HyvRV8gmChgHHNJaAqwoV8kjVsEVZhdW9nzA6PUgtX35LbViJPfu0LXxqSysWaR5S1PQcHdwFwVFYtTiS/6LnAZl+bc0U4goJgCPqeRS5dXmVcaMOmkAB5EnxBpFiZHrzxsVLqw1pzyZN8mG8iSXwoBrkoOoUDQ9NgAY19OwZoAldBosT1G7o6WUItPh49sW/I+Bvp2YokWo62Q0T4R5NSvNlEwRdlci4jSC1Ytm5nB/OF59b140DMwneQm4VNJrTBvgcqDj3xwWaiRtuOP57FXfSOoM0+EOLEEmVcBp26pBavtBSUmZX2Hc/F+5/Eh+zb5t5dF7LJoNDVE07G0bSaF06ZlSlA4Bh2Rt/C2gS7PeSgDpRasAKfTHcdAGCBt8X2CkH5ZDqicYL7rEFfOeZTpZ2WWW+q0TStEfAilbGposgo/SUl24YCu8dCtL6zI0YKAh1ILVtURkmLBhM640n2n+6wJZ8HZND176g8T/ooQAqeC06asyLqTfmvIR1CnUwa6fSRzXvniv9SCNTd40jiKaP/Mogg8RiyyNk9QXz5j5BgynDcmc8LEpty20I1BJkAlWD0iaWNNTU6dWHrDCW2eK+9mU7W9OyDYIqVeMLJM3Ig5bZZamlkOsk0nAiSEY9YnKo2VGlPjqkxRdOh3oXNJg6apBko2wTnalIvWQrqALL3qvoWSTLtUbag64VuuQf6u39CYxOR12NF0p+HL1FFewcoB6e4VpemFmATUkEUdkOR2a6bBmtMVPGf8MtpjY9FE2RFbVca6LjZdhw3t0KFgpkqHNX2OMlVprJ6gnfutAZ6wsdX2TJ1LJnRcv20Lu5tl7LGqXSTtZq11xn1K6C1Pzce8nIbUukBBTAgqlF6wZkN1uL9rzkmKRem0mxoUF9LmHNnIYl6j4tjWRLCOKTXtCpdMNltveBYqmeghvjbYhqwZGVE5rzxCK01R0y7qCupJ4Jrnreu4KLwGm4XAFCALzRGBalyUGU4KXngZYcbjkhFIMlt/2405wFUcfKB0gjU7SSiOtT4Gx2dwtgl0+4fXr9N/NAv5D6ZvqVP6YeMf3Qw2XXqUaAo2nW7zMR+S45+dCz7nnxeB12TX8nRhgtIJ1oYda/rvIu/IFB5LPx7e9DGWR5fLu6kpQNenRLTAvY937FTSs6GnbK8ayI6LrfMqiew9EVanFAULIYS1y9ja8FQ6wZqFssNFpkgqLUdA10ZL5PFqzJtG8WktijpWlCam1gt4dSS87yIYZzQ5dinlxpl1vlrR5u2vGpsw9YlNZRKzGUMZyitYJXGsOqAOpcoirRnY06EMh8keCW00Daq+Mq1btgn5HEsXB1Daxq+294cyDYUAZcKJla05870pyitYTWCjCRII7KIheSTMQpdvKg1axktoyHhwiRTJHuWN/VCes6Ko+96UnrGpw9IsVmmsFDAap/Yx3qvideP3FnZbbbh0lyjKSYcXz8KXd7RVmUqkfGe0adfNaHpsNepOfKOq2yaCQvq9BXTMFMbmGAKUQ7DK5rDEOeDLyyqDjzp17KFF0PxMoCdQM39nnJbBoeXab30Uscg64iAlHFv6g080+U0eMaAmtHVOLjq+iOl3NG0qh2CVwNUJU+SjexOizcPnUWj6Yz/fFWIjMGEhU9ZEcLi0VewkU5soVELLJipF/YFZcS2SOazR0gtWV28g9QL3NQlsPa8m9ISIYG4GYIm1r+FZtkKOe6LJphaXFWieqjmcNQWYIo+jNLXzKjRKL1hdUSiN1ZPDrBDaoQt4zZM0OUR7jTVWE34147Qp+AsK4vntc+2WUrAmd3FvE8hhzLzEiCrqk8F0ApLwHmur4YU+V0tUf6RXTuWEK8hGTS50Ciinjey4EYzWdCkFaxJ5GedVMJ3YoTXnvDV1k0QKW9qtL9J/mm7OzWLcXAMdO6ZrUw2+J5v7Fg7DUGFclcbqEapwktDClVufZjZUyMDxohwVrflwXFOhNhahR98ANrwWZeOkJUpPUoTSC1YdjTWkEPFhonAJUqfmxQgOgffki0hCz6cQ4tJWVUfQ9vzGfOqfPE9sCVK2/VB6wdqCYihipMhdu+QlIswg0N+ZYFAHcU79NFmiUKpUVq6/SI7c53gG5RWssb2rWAOiC5NJ6hpSpnNphhYYsWMrbxhkMqUQ+6kMNxyHJAEfMB1Lp7EPNeZE9ZRXsE7B6eYeDfiafNlytvxTaTN5bVCuyQsUfKvCobRpAMoTkxa/nI0wN/0hUL2m2rNvlF6wlhFkGqgrZItBN3rJgHeX7DMtGyuVcOU9azONLRdEmX95kIyjdC5V4VYa4ISA6GkCBnXonOwItWSfabmFM5fomBRCsKxpTjK59ET6X4cUzBSgDYuxsDrpFWiallOwFgSUwjD3xeMDolTYyLC9XBp0ER9CXjzFjUrLFki4AChMwgNgGR1jyb6xYH300Ufx1re+FQsWLEAURXjggQdS7xljWL9+PU455RTMnj0bQ0NDeP7551NlDhw4gJUrV6K3txdz587FqlWrcOjQoVSZn//85/iTP/kT9PT0YOHChbj11lvNWycDxQTMKRYy9GXMuaPJHsGx3QeMbw6LFO95MBjyog+nD1CsCcp1YCxYX375Zbz+9a/Hpk2buO9vvfVWbNy4EZs3b8b27dsxZ84cLFu2DIcPH47LrFy5Ert378bWrVvx4IMP4tFHH8Xq1avj9+Pj47jkkktw6qmnYufOnfjsZz+Lf/7nf8Zdd91l0cT2RG4ZYRzazhtAlEkTJUDozYDLuyELWo7/Ngzml4F0mFTN9N0NBvQ7TWlfdtlluOyyy7jvGGO4/fbbceONN+KKK64AAHz1q19Ff38/HnjgAVx11VV47rnnsGXLFjzxxBNYsmQJAOCOO+7A5Zdfjttuuw0LFizAfffdh6NHj+IrX/kKurq68NrXvha7du3C5z//+ZQApoSvAGMf8HEJttF9llRwib5RZcWpIhcsutApE09Sn+54cuvWiGxgEUPkOCmLLLyBpJOPIdvZedyERmpjffHFFzEyMoKhoaH4WV9fH5YuXYrh4WEAwPDwMObOnRsLVQAYGhpCrVbD9u3b4zJvectb0NXVFZdZtmwZ9uzZg9///vfcuo8cOYLx8fHUjwm0vK8e5AvFlWyFSLv1AVnQgAkPOVx7J4P0rgALlqxsh8bado4nBJ7p08DHYNS3WTKhbKwyjIyMAAD6+/tTz/v7++N3IyMjmD9/fup9Z2cn5s2blyrDo5GsI4sNGzagr68v/lm4cKF7g5IouN2K0iuavV1LNYm9ajMGbQrKB4O2zVc36sI4YaAdwBs/rVBcM7t10fwEMyYqYN26dRgbG4t/9u3blzdLTrDOlRY5qHXvIJBpU9SQkdXx5yT6yFUQOQsyndTN1HF16rNo+r+YToZbtTq8OEkIIpZZuo7CQsSi0pZq5gdo+/9BYGBgAAAwOjqaej46Ohq/GxgYwP79+1PvJyYmcODAgVQZHo1kHVl0d3ejt7c39UMB60GJwvyXu7pxuNZ3vHrWGPUD9OU2U+O2+VhrAhaCb0y8thUl80rFhyafQSNqOCnIKpAK1sWLF2NgYADbtm2Ln42Pj2P79u0YHBwEAAwODuLgwYPYuXNnXObhhx9GvV7H0qVL4zKPPvoojh07FpfZunUr/viP/xgnnngiJcteQWYn1Q3PkdgScz1a2tpKFSxLNVZqQcLzG9kKAc54atkBiex/ynp4VRNq9Dp1eE1a0UzscIGxYD106BB27dqFXbt2AWg4rHbt2oW9e/ciiiJcd911+NSnPoXvfve7ePrpp/H3f//3WLBgAa688koAwJlnnolLL70U11xzDXbs2IH//M//xNq1a3HVVVdhwYIFAIC/+7u/Q1dXF1atWoXdu3fjm9/8Jv7lX/4F119/vVNjXS+6MFq8RJekpAsalreBA2nju2Q1Q7Dawt7oMLe0QtHyTp6yFELGn5lsLCZkHYWo6ffG4VZPPvkk/t//+3/x301hd/XVV+Oee+7Bhz/8Ybz88stYvXo1Dh48iIsuughbtmxBT09P/M19992HtWvX4uKLL0atVsOKFSuwcePG+H1fXx9++MMfYs2aNTjvvPNw8sknY/369d5CrXRAsriTY2OUleNeNRVkIUe24Uh8gRzFNFvf8WnwM2cYUE/Yn7Nj4MELL/9Y/KrRhhoiZrCQuTZxeT1FQvZ/gsjjcnkfiBhj7d8KDsbHxxvRAZ/7JKI53QBLLAg29VPje2Kzz7KLVvZNxCKwGgO668Dh9IGg6ZxgnVNlJ9M0RZMqOlYDm1VPCQJu2cT72tEaWAdraSPv22wbU5OdodEeTnuT36X4n+IjLtsziehwR2s7a40+iOs7VgM6WepdjImoISO76sp2xKhhWrA2wxun+GJddWAiap0XUYbHrjpwtIZoIpqih7hsNBGh3lVvlO1g8bxK9kNUT7ShyRon9rT5Te1oDWwWax2Pzql21JHqP3QwREdr6TGbBFjPVPumnkVHIrDujE16ir+scEuWyY539n0KNaT6AABqr0Sod7FGX/XUp/tjaiyacys5BqyDpfotOhah3l1v9EFz7U5GrXOxxoAaQzTRehBn0RTNqFFnst3J/scsBkw2+jnbpvrhw/jfD63H2NiY0odjrLG2C5r7Rf3wYUS8MJbEIkq+4034ZvGYtkqwRgw4xoBj/LCk5iJMLbqpOlroYEr4TMiFY0v7E4IgK7Szv9c5z3lty6JFIGf6J34+UW8ITWR4yS7siQjoSC/6GJNTtCfF49XSJ03NrZ74u/n62LTAFQmUeBwnooaQryUEDGvQZZOJRZ3d9ASCNblRZXlnx2rABEewJhZ4tn2pzYlFMV/NdkcsagjZekawcnjg9UP29yyNlKBP1gmAHYvA6o2+ZqwupcGrF0Bjo6g3hGZ8fKvzN/nshpza+JuCVdB2FjHgaGIjBlJtqk9lj+roojNWY33hhRfwmte8Jm82KlSoMMOwb98+vPrVr5aWmbEa67x58wAAe/fuRV9fX87cFA/j4+NYuHAh9u3bRxaaNpNQ9Y8aZesjxhheeuml2Mkuw4wVrLVa4+jZ19dXikG3BWXM70xE1T9qlKmPdJW0GZN5VaFChQpFQSVYK1SoUIEYM1awdnd342Mf+xi6u7vzZqWQqPpHjqp/1Kj6SIwZGxVQoUKFCnlhxmqsFSpUqJAXKsFaoUKFCsSoBGuFChUqEKMSrBUqVKhAjEqwVqhQoQIxZqxg3bRpE0477TT09PRg6dKl2LFjR94seceGDRtw/vnn44QTTsD8+fNx5ZVXYs+ePakyhw8fxpo1a3DSSSfh+OOPx4oVK1r+t4a9e/di+fLlOO644zB//nzccMMNmJiYCNmUILjlllviO4SbKHv//OpXv8I73/lOnHTSSZg9ezbOOeccPPnkk/F7xhjWr1+PU045BbNnz8bQ0BCef/75FI0DBw5g5cqV6O3txdy5c7Fq1SocOnQodFPyBZuBuP/++1lXVxf7yle+wnbv3s2uueYaNnfuXDY6Opo3a16xbNkydvfdd7NnnnmG7dq1i11++eVs0aJF7NChQ3GZ9773vWzhwoVs27Zt7Mknn2QXXHABe/Ob3xy/n5iYYGeffTYbGhpiP/3pT9lDDz3ETj75ZLZu3bo8muQNO3bsYKeddhp73etexz74wQ/Gz8vcPwcOHGCnnnoqe/e73822b9/OXnjhBfaDH/yA/dd//Vdc5pZbbmF9fX3sgQceYD/72c/YX/7lX7LFixezV155JS5z6aWXste//vXs8ccfZ//xH//B/uiP/oi94x3vyKNJuWFGCtY3velNbM2aNfHfk5OTbMGCBWzDhg05chUe+/fvZwDYI488whhj7ODBg2zWrFnsW9/6VlzmueeeYwDY8PAwY4yxhx56iNVqNTYyMhKXufPOO1lvby87cuRI2AZ4wksvvcROP/10tnXrVvanf/qnsWAte/985CMfYRdddJHwfb1eZwMDA+yzn/1s/OzgwYOsu7ubfeMb32CMMfbss88yAOyJJ56Iy3z/+99nURSxX/3qV/6YLxhmnCng6NGj2LlzJ4aGhuJntVoNQ0NDGB4ezpGz8BgbGwMwfdPXzp07cezYsVTfnHHGGVi0aFHcN8PDwzjnnHNS//34smXLMD4+jt27dwfk3h/WrFmD5cuXp/oBqPrnu9/9LpYsWYK3v/3tmD9/Ps4991x8+ctfjt+/+OKLGBkZSfVPX18fli5dmuqfuXPnYsmSJXGZoaEh1Go1bN++PVxjcsaME6y/+93vMDk5mZr4ANDf34+RkZGcuAqPer2O6667DhdeeCHOPvtsAMDIyAi6urowd+7cVNlk34yMjHD7rvmu3XH//ffjqaeewoYNG1relb1/XnjhBdx55504/fTT8YMf/ADXXnstPvCBD+Dee+8FMN0+2doaGRnB/PnzU+87Ozsxb968tu8fE8zYawPLjjVr1uCZZ57BT37yk7xZKQz27duHD37wg9i6dWvq/2Cr0EC9XseSJUtw8803AwDOPfdcPPPMM9i8eTOuvvrqnLlrL8w4jfXkk09GR0dHiyd3dHQUAwMDOXEVFmvXrsWDDz6IH/3oR6mbzgcGBnD06FEcPHgwVT7ZNwMDA9y+a75rZ+zcuRP79+/HG9/4RnR2dqKzsxOPPPIINm7ciM7OTvT395e6f0455RScddZZqWdnnnkm9u7dC2C6fbK1NTAwgP3796feT0xM4MCBA23fPyaYcYK1q6sL5513HrZt2xY/q9fr2LZtGwYHB3PkzD8YY1i7di2+/e1v4+GHH8bixYtT78877zzMmjUr1Td79uzB3r17474ZHBzE008/nVocW7duRW9vb8uiazdcfPHFePrpp+P/vn3Xrl1YsmQJVq5cGf9e5v658MILW8LzfvnLX+LUU08FACxevBgDAwOp/hkfH8f27dtT/XPw4EHs3LkzLvPwww+jXq9j6dKlAVpREOTtPfOB+++/n3V3d7N77rmHPfvss2z16tVs7ty5KU/uTMS1117L+vr62I9//GP2m9/8Jv75wx/+EJd573vfyxYtWsQefvhh9uSTT7LBwUE2ODgYv2+GE11yySVs165dbMuWLexVr3rVjAgn4iEZFcBYuftnx44drLOzk336059mzz//PLvvvvvYcccdx772ta/FZW655RY2d+5c9p3vfIf9/Oc/Z1dccQU33Orcc89l27dvZz/5yU/Y6aefXoVbzRTccccdbNGiRayrq4u96U1vYo8//njeLHkHpv8fz9TP3XffHZd55ZVX2Pve9z524oknsuOOO4791V/9FfvNb36TovPf//3f7LLLLmOzZ89mJ598Mvunf/onduzYscCtCYOsYC17/3zve99jZ599Nuvu7mZnnHEGu+uuu1Lv6/U6u+mmm1h/fz/r7u5mF198MduzZ0+qzP/93/+xd7zjHez4449nvb297D3veQ976aWXQjYjd1T3sVaoUKECMWacjbVChQoV8kYlWCtUqFCBGJVgrVChQgViVIK1QoUKFYhRCdYKFSpUIEYlWCtUqFCBGJVgrVChQgViVIK1QoUKFYhRCdYKFSpUIEYlWCtUqFCBGJVgrVChQgVi/P+dX9pOqv2JSQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(GPT2.transformer.wpe.weight.detach().cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
